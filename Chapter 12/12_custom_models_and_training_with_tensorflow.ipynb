{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chapter 12 – Custom Models and Training with TensorFlow**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_This notebook contains all the sample code and solutions to the exercises in chapter 12, as well as code examples from Appendix C_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project requires Python 3.7 or above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "assert sys.version_info >= (3, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And TensorFlow ≥ 2.8:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from packaging import version\n",
    "import tensorflow as tf\n",
    "\n",
    "assert version.parse(tf.__version__) >= version.parse(\"2.8.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using TensorFlow like NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors and Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tf.constant([[1., 2., 3.], [4., 5., 6.]]) # matrix\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[2., 3.],\n",
       "       [5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[2.],\n",
       "       [5.]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[..., 1, tf.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[11., 12., 13.],\n",
       "       [14., 15., 16.]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[ 1.,  4.,  9.],\n",
       "       [16., 25., 36.]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[14., 32.],\n",
       "       [32., 77.]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t @ tf.transpose(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scalars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=42>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keras's low-level API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may still run across code that uses Keras's low-level API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[11., 26.],\n",
       "       [14., 35.],\n",
       "       [19., 46.]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = tf.keras.backend\n",
    "K.square(K.transpose(t)) + 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But since Keras does not support multiple backends anymore, you should instead use TF's low-level API directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[11., 26.],\n",
       "       [14., 35.],\n",
       "       [19., 46.]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(tf.transpose(t)) + 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors and NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([2., 4., 5.])>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([2., 4., 5.])\n",
    "tf.constant(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([ 4., 16., 25.])>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  4.,  9.],\n",
       "       [16., 25., 36.]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.square(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type Conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a int32 tensor [Op:AddV2] name: \n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tf.constant(2.0) + tf.constant(40)\n",
    "except tf.errors.InvalidArgumentError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a double tensor [Op:AddV2] name: \n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tf.constant(2.0) + tf.constant(40., dtype=tf.float64)\n",
    "except tf.errors.InvalidArgumentError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=42.0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = tf.constant(40., dtype=tf.float64)\n",
    "tf.constant(2.0) + tf.cast(t2, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = tf.Variable([[1., 2., 3.], [4., 5., 6.]])\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2.,  4.,  6.],\n",
       "       [ 8., 10., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.assign(2 * v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2., 42.,  6.],\n",
       "       [ 8., 10., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[0, 1].assign(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2., 42.,  0.],\n",
       "       [ 8., 10.,  1.]], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[:, 2].assign([0., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[100.,  42.,   0.],\n",
       "       [  8.,  10., 200.]], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.scatter_nd_update(\n",
    "    indices=[[0, 0], [1, 2]], updates=[100., 200.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[4., 5., 6.],\n",
       "       [1., 2., 3.]], dtype=float32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – shows how to use scatter_update()\n",
    "sparse_delta = tf.IndexedSlices(values=[[1., 2., 3.], [4., 5., 6.]],\n",
    "                                indices=[1, 0])\n",
    "v.scatter_update(sparse_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ResourceVariable' object does not support item assignment\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    v[1] = [7., 8., 9.]\n",
    "except TypeError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in this section and all the following sections  in appendix C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'hello world'>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(b\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'caf\\xc3\\xa9'>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(\"café\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([ 99,  97, 102, 233])>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = tf.constant([ord(c) for c in \"café\"])\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=4>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = tf.strings.unicode_encode(u, \"UTF-8\")\n",
    "tf.strings.length(b, unit=\"UTF8_CHAR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([ 99,  97, 102, 233])>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_decode(b, \"UTF-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Data Structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in this section is in Appendix C."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### String arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'hello world'>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(b\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'caf\\xc3\\xa9'>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(\"café\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([ 99,  97, 102, 233])>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = tf.constant([ord(c) for c in \"café\"])\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'caf\\xc3\\xa9'>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = tf.strings.unicode_encode(u, \"UTF-8\")\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=4>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.length(b, unit=\"UTF8_CHAR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([ 99,  97, 102, 233])>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_decode(b, \"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = tf.constant([\"Café\", \"Coffee\", \"caffè\", \"咖啡\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([4, 6, 5, 2])>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.length(p, unit=\"UTF8_CHAR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[67, 97, 102, 233], [67, 111, 102, 102, 101, 101],\n",
       " [99, 97, 102, 102, 232], [21654, 21857]]>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = tf.strings.unicode_decode(p, \"UTF8\")\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ragged tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6,), dtype=int32, numpy=array([ 67, 111, 102, 102, 101, 101])>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[67, 111, 102, 102, 101, 101], [99, 97, 102, 102, 232]]>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[1:3]  # extra code – a slice of a ragged tensor is a ragged tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[67, 97, 102, 233], [67, 111, 102, 102, 101, 101],\n",
       " [99, 97, 102, 102, 232], [21654, 21857], [65, 66], [], [67]]>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2 = tf.ragged.constant([[65, 66], [], [67]])\n",
    "tf.concat([r, r2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[67, 97, 102, 233, 68, 69, 70], [67, 111, 102, 102, 101, 101, 71],\n",
      " [99, 97, 102, 102, 232], [21654, 21857, 72, 73]]>\n"
     ]
    }
   ],
   "source": [
    "r3 = tf.ragged.constant([[68, 69, 70], [71], [], [72, 73]])\n",
    "print(tf.concat([r, r3], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 6), dtype=int32, numpy=\n",
       "array([[   67,    97,   102,   233,     0,     0],\n",
       "       [   67,   111,   102,   102,   101,   101],\n",
       "       [   99,    97,   102,   102,   232,     0],\n",
       "       [21654, 21857,     0,     0,     0,     0]])>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.to_tensor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sparse tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = tf.SparseTensor(indices=[[0, 1], [1, 0], [2, 3]],\n",
    "                    values=[1., 2., 3.],\n",
    "                    dense_shape=[3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
       "array([[0., 1., 0., 0.],\n",
       "       [2., 0., 0., 0.],\n",
       "       [0., 0., 0., 3.]], dtype=float32)>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sparse.to_dense(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseTensor(indices=tf.Tensor(\n",
       "[[0 1]\n",
       " [1 0]\n",
       " [2 3]], shape=(3, 2), dtype=int64), values=tf.Tensor([ 42.  84. 126.], shape=(3,), dtype=float32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s * 42.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unsupported operand type(s) for +: 'SparseTensor' and 'float'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    s + 42.0\n",
    "except TypeError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[ 30.,  40.],\n",
       "       [ 20.,  40.],\n",
       "       [210., 240.]], dtype=float32)>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – shows how to multiply a sparse tensor and a dense tensor\n",
    "s4 = tf.constant([[10., 20.], [30., 40.], [50., 60.], [70., 80.]])\n",
    "tf.sparse.sparse_dense_matmul(s, s4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{{function_node __wrapped__SparseToDense_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[1] = [0,1] is out of order. Many sparse ops require sorted indices.\n",
      "    Use `tf.sparse.reorder` to create a correctly ordered copy.\n",
      "\n",
      " [Op:SparseToDense] name: \n"
     ]
    }
   ],
   "source": [
    "# extra code – when creating a sparse tensor, values must be given in \"reading\n",
    "#              order\", or else `to_dense()` will fail.\n",
    "s5 = tf.SparseTensor(indices=[[0, 2], [0, 1]],  # WRONG ORDER!\n",
    "                     values=[1., 2.],\n",
    "                     dense_shape=[3, 4])\n",
    "try:\n",
    "    tf.sparse.to_dense(s5)\n",
    "except tf.errors.InvalidArgumentError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
       "array([[0., 2., 1., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – shows how to fix the sparse tensor s5 by reordering its values\n",
    "s6 = tf.sparse.reorder(s5)\n",
    "tf.sparse.to_dense(s6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensor Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = tf.TensorArray(dtype=tf.float32, size=3)\n",
    "array = array.write(0, tf.constant([1., 2.]))\n",
    "array = array.write(1, tf.constant([3., 10.]))\n",
    "array = array.write(2, tf.constant([5., 7.]))\n",
    "tensor1 = array.read(1)  # returns (and zeros out!) tf.constant([3., 10.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[1., 2.],\n",
       "       [0., 0.],\n",
       "       [5., 7.]], dtype=float32)>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[ 1.,  2.],\n",
       "       [ 3., 10.],\n",
       "       [ 5.,  7.]], dtype=float32)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – shows how to disable clear_after_read\n",
    "array2 = tf.TensorArray(dtype=tf.float32, size=3, clear_after_read=False)\n",
    "array2 = array2.write(0, tf.constant([1., 2.]))\n",
    "array2 = array2.write(1, tf.constant([3., 10.]))\n",
    "array2 = array2.write(2, tf.constant([5., 7.]))\n",
    "tensor2 = array2.read(1)  # returns tf.constant([3., 10.])\n",
    "array2.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[1., 2.],\n",
       "       [0., 0.],\n",
       "       [5., 7.]], dtype=float32)>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – shows how to create and use a tensor array with a dynamic size\n",
    "array3 = tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True)\n",
    "array3 = array3.write(0, tf.constant([1., 2.]))\n",
    "array3 = array3.write(1, tf.constant([3., 10.]))\n",
    "array3 = array3.write(2, tf.constant([5., 7.]))\n",
    "tensor3 = array3.read(1)\n",
    "array3.stack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseTensor(indices=tf.Tensor(\n",
       "[[0 0]\n",
       " [0 1]\n",
       " [0 2]\n",
       " [0 3]\n",
       " [0 4]], shape=(5, 2), dtype=int64), values=tf.Tensor([ 1  5  6  9 11], shape=(5,), dtype=int32), dense_shape=tf.Tensor([1 5], shape=(2,), dtype=int64))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant([[1, 5, 9]])\n",
    "b = tf.constant([[5, 6, 9, 11]])\n",
    "u = tf.sets.union(a, b)\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 5), dtype=int32, numpy=array([[ 1,  5,  6,  9, 11]])>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sparse.to_dense(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 5), dtype=int32, numpy=\n",
       "array([[ 1,  5,  6,  9, 11],\n",
       "       [ 0, 10, 13,  0,  0]])>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant([[1, 5, 9], [10, 0, 0]])\n",
    "b = tf.constant([[5, 6, 9, 11], [13, 0, 0, 0]])\n",
    "u = tf.sets.union(a, b)\n",
    "tf.sparse.to_dense(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 5), dtype=int32, numpy=\n",
       "array([[ 1,  5,  6,  9, 11],\n",
       "       [-1, 10, 13, -1, -1]])>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – shows how to use a different default value: -1 in this case\n",
    "a = tf.constant([[1, 5, 9], [10, -1, -1]])\n",
    "b = tf.constant([[5, 6, 9, 11], [13, -1, -1, -1]])\n",
    "u = tf.sets.union(a, b)\n",
    "tf.sparse.to_dense(u, default_value=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[2, 3, 7],\n",
       "       [7, 0, 0]])>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – shows how to use `tf.sets.difference()`\n",
    "set1 = tf.constant([[2, 3, 5, 7], [7, 9, 0, 0]])\n",
    "set2 = tf.constant([[4, 5, 6], [9, 10, 0]])\n",
    "tf.sparse.to_dense(tf.sets.difference(set1, set2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[5, 0],\n",
       "       [0, 9]])>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – shows how to use `tf.sets.difference()`\n",
    "tf.sparse.to_dense(tf.sets.intersection(set1, set2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – check whether set1[0] contains 5\n",
    "tf.sets.size(tf.sets.intersection(set1[:1], tf.constant([[5, 0, 0, 0]]))) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Queues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=2>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = tf.queue.FIFOQueue(3, [tf.int32, tf.string], shapes=[(), ()])\n",
    "q.enqueue([10, b\"windy\"])\n",
    "q.enqueue([15, b\"sunny\"])\n",
    "q.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=int32, numpy=10>,\n",
       " <tf.Tensor: shape=(), dtype=string, numpy=b'windy'>]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.dequeue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "q.enqueue_many([[13, 16], [b'cloudy', b'rainy']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(3,), dtype=int32, numpy=array([15, 13, 16])>,\n",
       " <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'sunny', b'cloudy', b'rainy'], dtype=object)>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.dequeue_many(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber_fn(y_true, y_pred):\n",
    "    error = y_true - y_pred\n",
    "    is_small_error = tf.abs(error) < 1\n",
    "    squared_loss = tf.square(error) / 2\n",
    "    linear_loss  = tf.abs(error) - 0.5\n",
    "    return tf.where(is_small_error, squared_loss, linear_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x350 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# extra code – shows what the Huber loss looks like\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 3.5))\n",
    "z = np.linspace(-4, 4, 200)\n",
    "z_center = np.linspace(-1, 1, 200)\n",
    "plt.plot(z, huber_fn(0, z), \"b-\", linewidth=2, label=\"huber($z$)\")\n",
    "plt.plot(z, z ** 2 / 2, \"r:\", linewidth=1)\n",
    "plt.plot(z_center, z_center ** 2 / 2, \"r\", linewidth=2)\n",
    "plt.plot([-1, -1], [0, huber_fn(0., -1.)], \"k--\")\n",
    "plt.plot([1, 1], [0, huber_fn(0., 1.)], \"k--\")\n",
    "plt.gca().axhline(y=0, color='k')\n",
    "plt.gca().axvline(x=0, color='k')\n",
    "plt.text(2.1, 3.5, r\"$\\frac{1}{2}z^2$\", color=\"r\", fontsize=15)\n",
    "plt.text(3.0, 2.2, r\"$|z| - \\frac{1}{2}$\", color=\"b\", fontsize=15)\n",
    "plt.axis([-4, 4, 0, 4])\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"$z$\")\n",
    "plt.legend(fontsize=14)\n",
    "plt.title(\"Huber loss\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test our custom loss function, let's create a basic Keras model and train it on the California housing dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Devon Tamaam Adira S\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# extra code – loads, splits and scales the California housing dataset, then\n",
    "#              creates a simple Keras model\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target.reshape(-1, 1), random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(30, activation=\"relu\", kernel_initializer=\"he_normal\",\n",
    "                          input_shape=input_shape),\n",
    "    tf.keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=huber_fn, optimizer=\"nadam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.7494 - mae: 1.1371 - val_loss: 0.3474 - val_mae: 0.6522\n",
      "Epoch 2/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2607 - mae: 0.5681 - val_loss: 0.2553 - val_mae: 0.5383\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e381c881d0>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving/Loading Models with Custom Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_a_custom_loss.keras\")  # extra code – saving works fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"my_model_with_a_custom_loss.keras\",\n",
    "                                   custom_objects={\"huber_fn\": huber_fn})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.2188 - mae: 0.5096 - val_loss: 0.2129 - val_mae: 0.4876\n",
      "Epoch 2/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1990 - mae: 0.4809 - val_loss: 0.1891 - val_mae: 0.4610\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e3861cd670>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_huber(threshold=1.0):\n",
    "    def huber_fn(y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss  = threshold * tf.abs(error) - threshold ** 2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    return huber_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=create_huber(2.0), optimizer=\"nadam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.2148 - mae: 0.4689 - val_loss: 0.2084 - val_mae: 0.4504\n",
      "Epoch 2/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2054 - mae: 0.4597 - val_loss: 0.1807 - val_mae: 0.4340\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e381ee4c20>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_a_custom_loss_threshold_2.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"my_model_with_a_custom_loss_threshold_2.keras\",\n",
    "                                   custom_objects={\"huber_fn\": create_huber(2.0)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.2000 - mae: 0.4540 - val_loss: 0.1853 - val_mae: 0.4339\n",
      "Epoch 2/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1959 - mae: 0.4490 - val_loss: 0.1976 - val_mae: 0.4367\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e381ee6930>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, threshold=1.0, **kwargs):\n",
    "        self.threshold = threshold\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < self.threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss  = self.threshold * tf.abs(error) - self.threshold**2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra code – creates another basic Keras model\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(30, activation=\"relu\", kernel_initializer=\"he_normal\",\n",
    "                          input_shape=input_shape),\n",
    "    tf.keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=HuberLoss(2.), optimizer=\"nadam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.0512 - mae: 1.1438 - val_loss: 0.5086 - val_mae: 0.6718\n",
      "Epoch 2/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3170 - mae: 0.5816 - val_loss: 0.3527 - val_mae: 0.5571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e386487dd0>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_a_custom_loss_class.keras\")  # extra code – saving works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"my_model_with_a_custom_loss_class.keras\",\n",
    "                                   custom_objects={\"HuberLoss\": HuberLoss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.2612 - mae: 0.5244 - val_loss: 0.2689 - val_mae: 0.4982\n",
      "Epoch 2/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2328 - mae: 0.4929 - val_loss: 0.2207 - val_mae: 0.4657\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e386366930>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – shows that loading worked fine, the model can be used normally\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.loss.threshold  # extra code – the treshold was loaded correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Custom Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_softplus(z):\n",
    "    return tf.math.log(1.0 + tf.exp(z))\n",
    "\n",
    "def my_glorot_initializer(shape, dtype=tf.float32):\n",
    "    stddev = tf.sqrt(2. / (shape[0] + shape[1]))\n",
    "    return tf.random.normal(shape, stddev=stddev, dtype=dtype)\n",
    "\n",
    "def my_l1_regularizer(weights):\n",
    "    return tf.reduce_sum(tf.abs(0.01 * weights))\n",
    "\n",
    "def my_positive_weights(weights):  # return value is just tf.nn.relu(weights)\n",
    "    return tf.where(weights < 0., tf.zeros_like(weights), weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = tf.keras.layers.Dense(1, activation=my_softplus,\n",
    "                              kernel_initializer=my_glorot_initializer,\n",
    "                              kernel_regularizer=my_l1_regularizer,\n",
    "                              kernel_constraint=my_positive_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyL1Regularizer(tf.keras.regularizers.Regularizer):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "\n",
    "    def __call__(self, weights):\n",
    "        return tf.reduce_sum(tf.abs(self.factor * weights))\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\"factor\": self.factor}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra code – once again, lets' create a basic Keras model\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(30, activation=\"relu\", kernel_initializer=\"he_normal\",\n",
    "                          input_shape=input_shape),\n",
    "    tf.keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[create_huber(2.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - huber_fn: 1.0788 - loss: 2.5942\n",
      "Epoch 2/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - huber_fn: 0.3403 - loss: 0.7644\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e3865f0ad0>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – train the model with our custom metric\n",
    "model.fit(X_train_scaled, y_train, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: if you use the same function as the loss and a metric, you may be surprised to see slightly different results. This is in part because the operations are not computed exactly in the same order, so there might be tiny floating point errors. More importantly, if you use sample weights or class weights, then the equations are a bit different:\n",
    "* the `fit()` method keeps track of the mean of all batch losses seen so far since the start of the epoch. Each batch loss is the sum of the weighted instance losses divided by the _batch size_ (not the sum of weights, so the batch loss is _not_ the weighted mean of the losses).\n",
    "* the metric since the start of the epoch is equal to the sum of weighted instance losses divided by sum of all weights seen so far. In other words, it is the weighted mean of all the instance losses. Not the same thing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.8>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = tf.keras.metrics.Precision()\n",
    "precision([0, 1, 1, 1, 0, 1, 0, 1], [1, 1, 0, 1, 0, 1, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision([0, 1, 0, 0, 1, 0, 1, 1], [1, 0, 1, 1, 0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Variable path=precision/true_positives, shape=(1,), dtype=float32, value=[4.]>,\n",
       " <Variable path=precision/false_positives, shape=(1,), dtype=float32, value=[4.]>]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning**: the `reset_states()` method was renamed to `reset_state()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a streaming metric:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning**: the `add_weight()` method's argument have a different order now, so we have to specify `name=\"total\"` and `name=\"count\"` rather than just passing the name as the first argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberMetric(tf.keras.metrics.Metric):\n",
    "    def __init__(self, threshold=1.0, **kwargs):\n",
    "        super().__init__(**kwargs)  # handles base args (e.g., dtype)\n",
    "        self.threshold = threshold\n",
    "        self.huber_fn = create_huber(threshold)\n",
    "        self.total = self.add_weight(name=\"total\", initializer=\"zeros\")\n",
    "        self.count = self.add_weight(name=\"count\", initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        sample_metrics = self.huber_fn(y_true, y_pred)\n",
    "        self.total.assign_add(tf.reduce_sum(sample_metrics))\n",
    "        self.count.assign_add(tf.cast(tf.size(y_true), tf.float32))\n",
    "\n",
    "    def result(self):\n",
    "        return self.total / self.count\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extra material** – the rest of this section tests the `HuberMetric` class and shows another implementation subclassing `tf.keras.metrics.Mean`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=14.0>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = HuberMetric(2.)\n",
    "\n",
    "# total = 2 * |10 - 2| - 2²/2 = 14\n",
    "# count = 1\n",
    "# result = 14 / 1 = 14\n",
    "m(tf.constant([[2.]]), tf.constant([[10.]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=7.0>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total = total + (|1 - 0|² / 2) + (2 * |9.25 - 5| - 2² / 2) = 14 + 7 = 21\n",
    "# count = count + 2 = 3\n",
    "# result = total / count = 21 / 3 = 7\n",
    "m(tf.constant([[0.], [5.]]), tf.constant([[1.], [9.25]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=7.0>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Variable path=huber_metric/total, shape=(), dtype=float32, value=21.0>,\n",
       " <Variable path=huber_metric/count, shape=(), dtype=float32, value=3.0>]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Variable path=huber_metric/total, shape=(), dtype=float32, value=0.0>,\n",
       " <Variable path=huber_metric/count, shape=(), dtype=float32, value=0.0>]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.reset_state()\n",
    "m.variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that the `HuberMetric` class works well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.set_random_seed(42)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(30, activation=\"relu\", kernel_initializer=\"he_normal\",\n",
    "                          input_shape=input_shape),\n",
    "    tf.keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=create_huber(2.0), optimizer=\"nadam\",\n",
    "              metrics=[HuberMetric(2.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - huber_metric_1: 1.0512 - loss: 1.0512\n",
      "Epoch 2/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - huber_metric_1: 0.3170 - loss: 0.3170\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e386b525d0>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_a_custom_metric.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\n",
    "    \"my_model_with_a_custom_metric.keras\",\n",
    "    custom_objects={\n",
    "        \"huber_fn\": create_huber(2.0),\n",
    "        \"HuberMetric\": HuberMetric\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - huber_metric_1: 0.2612 - loss: 0.2612  \n",
      "Epoch 2/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - huber_metric_1: 0.2328 - loss: 0.2328\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e381f5cb90>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like it works fine! More simply, we could have created the class like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberMetric(tf.keras.metrics.Mean):\n",
    "    def __init__(self, threshold=1.0, name='HuberMetric', dtype=None):\n",
    "        self.threshold = threshold\n",
    "        self.huber_fn = create_huber(threshold)\n",
    "        super().__init__(name=name, dtype=dtype)\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        metric = self.huber_fn(y_true, y_pred)\n",
    "        super(HuberMetric, self).update_state(metric, sample_weight)\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class handles shapes better, and it also supports sample weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.set_random_seed(42)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(30, activation=\"relu\", kernel_initializer=\"he_normal\",\n",
    "                          input_shape=input_shape),\n",
    "    tf.keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.Huber(2.0), optimizer=\"nadam\",\n",
    "              weighted_metrics=[HuberMetric(2.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - HuberMetric: 1.0599 - loss: 0.5274\n",
      "Epoch 2/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - HuberMetric: 0.3215 - loss: 0.1598\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "sample_weight = np.random.rand(len(y_train))\n",
    "history = model.fit(X_train_scaled, y_train, epochs=2,\n",
    "                    sample_weight=sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3256884217262268, 0.32568849524955656)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(history.history[\"loss\"][0],\n",
    " history.history[\"HuberMetric\"][0] * sample_weight.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_a_custom_metric_v2.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"my_model_with_a_custom_metric_v2.keras\",\n",
    "                                   custom_objects={\"HuberMetric\": HuberMetric})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - HuberMetric: 0.2627 - loss: 0.2262\n",
      "Epoch 2/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - HuberMetric: 0.2298 - loss: 0.1999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e386f261e0>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "exponential_layer = tf.keras.layers.Lambda(lambda x: tf.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.36787945, 1.        , 2.7182817 ], dtype=float32)>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – like all layers, it can be used as a function:\n",
    "exponential_layer(tf.constant([-1., 0., 1.]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding an exponential layer at the output of a regression model can be useful if the values to predict are positive and with very different scales (e.g., 0.001, 10., 10000)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Devon Tamaam Adira S\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "Epoch 1/5\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.2350 - val_loss: 0.4393\n",
      "Epoch 2/5\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6130 - val_loss: 0.4048\n",
      "Epoch 3/5\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5171 - val_loss: 0.3942\n",
      "Epoch 4/5\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4498 - val_loss: 0.3699\n",
      "Epoch 5/5\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5428 - val_loss: 0.3756\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - loss: 0.3909\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3936251401901245"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(42)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(30, activation=\"relu\", input_shape=input_shape),\n",
    "    tf.keras.layers.Dense(1),\n",
    "    exponential_layer\n",
    "])\n",
    "model.compile(loss=\"mse\", optimizer=\"sgd\")\n",
    "model.fit(X_train_scaled, y_train, epochs=5,\n",
    "          validation_data=(X_valid_scaled, y_valid))\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, it's often preferable to replace the targets with the logarithm of the targets (and use no activation function in the output layer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDense(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, activation=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        self.kernel = self.add_weight(\n",
    "            name=\"kernel\", shape=[batch_input_shape[-1], self.units],\n",
    "            initializer=\"he_normal\")\n",
    "        self.bias = self.add_weight(\n",
    "            name=\"bias\", shape=[self.units], initializer=\"zeros\")\n",
    "\n",
    "    def call(self, X):\n",
    "        return self.activation(X @ self.kernel + self.bias)\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"units\": self.units,\n",
    "                \"activation\": tf.keras.activations.serialize(self.activation)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Devon Tamaam Adira S\\AppData\\Local\\Temp\\ipykernel_26272\\3097604586.py:3: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5.7265 - val_loss: 6.9255\n",
      "Epoch 2/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9550 - val_loss: 2.6011\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7227  \n"
     ]
    }
   ],
   "source": [
    "# extra code – shows that a custom layer can be used normally\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "model = tf.keras.Sequential([\n",
    "    MyDense(30, activation=\"relu\", input_shape=input_shape),\n",
    "    MyDense(1)\n",
    "])\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))\n",
    "model.evaluate(X_test_scaled, y_test)\n",
    "model.save(\"my_model_with_a_custom_layer.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.7034 - val_loss: 0.8613\n",
      "Epoch 2/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5803 - val_loss: 0.4588\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e386ba2030>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – shows how to load a model with a custom layer\n",
    "model = tf.keras.models.load_model(\"my_model_with_a_custom_layer.keras\",\n",
    "                                   custom_objects={\"MyDense\": MyDense})\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMultiLayer(tf.keras.layers.Layer):\n",
    "    def call(self, X):\n",
    "        X1, X2 = X\n",
    "        print(\"X1.shape: \", X1.shape ,\" X2.shape: \", X2.shape)  # extra code\n",
    "        return X1 + X2, X1 * X2, X1 / X2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our custom layer can be called using the functional API like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1.shape:  (None, 2)  X2.shape:  (None, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<KerasTensor shape=(None, 2), dtype=float32, sparse=False, ragged=False, name=keras_tensor_44>,\n",
       " <KerasTensor shape=(None, 2), dtype=float32, sparse=False, ragged=False, name=keras_tensor_45>,\n",
       " <KerasTensor shape=(None, 2), dtype=float32, sparse=False, ragged=False, name=keras_tensor_46>)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – tests MyMultiLayer with symbolic inputs\n",
    "inputs1 = tf.keras.layers.Input(shape=[2])\n",
    "inputs2 = tf.keras.layers.Input(shape=[2])\n",
    "MyMultiLayer()((inputs1, inputs2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `call()` method receives symbolic inputs, and it returns symbolic outputs. The shapes are only partially specified at this stage: we don't know the batch size, which is why the first dimension is `None`.\n",
    "\n",
    "We can also pass actual data to the custom layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1.shape:  (2, 2)  X2.shape:  (2, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       " array([[ 9., 18.],\n",
       "        [ 6., 10.]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       " array([[18., 72.],\n",
       "        [ 8., 21.]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       " array([[0.5      , 0.5      ],\n",
       "        [0.5      , 2.3333333]], dtype=float32)>)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – tests MyMultiLayer with actual data \n",
    "X1, X2 = np.array([[3., 6.], [2., 7.]]), np.array([[6., 12.], [4., 3.]]) \n",
    "MyMultiLayer()((X1, X2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a layer with a different behavior during training and testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGaussianNoise(tf.keras.layers.Layer):\n",
    "    def __init__(self, stddev, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.stddev = stddev\n",
    "\n",
    "    def call(self, X, training=None):\n",
    "        if training:\n",
    "            noise = tf.random.normal(tf.shape(X), stddev=self.stddev)\n",
    "            return X + noise\n",
    "        else:\n",
    "            return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a simple model that uses this custom layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Devon Tamaam Adira S\\AppData\\Local\\Temp\\ipykernel_26272\\3716225758.py:3: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 2.7619 - val_loss: 25.1369\n",
      "Epoch 2/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.3951 - val_loss: 14.9793\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - loss: 1.1219\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.1244221925735474"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – tests MyGaussianNoise\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "model = tf.keras.Sequential([\n",
    "    MyGaussianNoise(stddev=1.0, input_shape=input_shape),\n",
    "    tf.keras.layers.Dense(30, activation=\"relu\",\n",
    "                          kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, n_layers, n_neurons, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden = [tf.keras.layers.Dense(n_neurons, activation=\"relu\",\n",
    "                                             kernel_initializer=\"he_normal\")\n",
    "                       for _ in range(n_layers)]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        return inputs + Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualRegressor(tf.keras.Model):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden1 = tf.keras.layers.Dense(30, activation=\"relu\",\n",
    "                                             kernel_initializer=\"he_normal\")\n",
    "        self.block1 = ResidualBlock(2, 30)\n",
    "        self.block2 = ResidualBlock(2, 30)\n",
    "        self.out = tf.keras.layers.Dense(output_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = self.hidden1(inputs)\n",
    "        for _ in range(1 + 3):\n",
    "            Z = self.block1(Z)\n",
    "        Z = self.block2(Z)\n",
    "        return self.out(Z)\n",
    "\n",
    "    # extra code - to be able to save and load the model below\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"output_dim\": self.output_dim}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 123.5810\n",
      "Epoch 2/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.5416\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1640\n"
     ]
    }
   ],
   "source": [
    "# extra code – shows that the model can be used normally\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "model = ResidualRegressor(1)\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=2)\n",
    "score = model.evaluate(X_test_scaled, y_test)\n",
    "model.save(\"my_custom_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.0556\n",
      "Epoch 2/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9670\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.70057404],\n",
       "       [1.1116575 ],\n",
       "       [3.8891037 ]], dtype=float32)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – the model can be loaded and you can continue training or use it\n",
    "#              to make predictions\n",
    "model = tf.keras.models.load_model(\n",
    "    \"my_custom_model.keras\",\n",
    "    custom_objects={\"ResidualRegressor\": ResidualRegressor}\n",
    ")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=2)\n",
    "model.predict(X_test_scaled[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could have defined the model using the sequential API instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.set_random_seed(42)\n",
    "block1 = ResidualBlock(2, 30)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(30, activation=\"relu\",\n",
    "                          kernel_initializer=\"he_normal\"),\n",
    "    block1, block1, block1, block1,\n",
    "    ResidualBlock(2, 30),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Losses Based on Model Internals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning**: the `add_metric()` method was deprecated and removed in recent TF versions. Metrics (custom or not) must now be passed to the model via the `metrics` argument of the `model.compile()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReconstructingRegressor(tf.keras.Model):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden = [tf.keras.layers.Dense(30, activation=\"relu\",\n",
    "                                             kernel_initializer=\"he_normal\")\n",
    "                       for _ in range(5)]\n",
    "        self.out = tf.keras.layers.Dense(output_dim)\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        n_inputs = batch_input_shape[-1]\n",
    "        self.reconstruct = tf.keras.layers.Dense(n_inputs)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        Z = inputs\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        reconstruction = self.reconstruct(Z)\n",
    "        recon_loss = tf.reduce_mean(tf.square(reconstruction - inputs))\n",
    "        self.add_loss(0.05 * recon_loss)\n",
    "        return self.out(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 1.1051\n",
      "Epoch 2/5\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5082\n",
      "Epoch 3/5\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4392\n",
      "Epoch 4/5\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3985\n",
      "Epoch 5/5\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3805\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# extra code\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "model = ReconstructingRegressor(1)\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=5)\n",
    "y_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Gradients Using Autodiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(w1, w2):\n",
    "    return 3 * w1 ** 2 + 2 * w1 * w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.000003007075065"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1, w2 = 5, 3\n",
    "eps = 1e-6\n",
    "(f(w1 + eps, w2) - f(w1, w2)) / eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.000000003174137"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(f(w1, w2 + eps) - f(w1, w2)) / eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, w2 = tf.Variable(5.), tf.Variable(3.)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)\n",
    "\n",
    "gradients = tape.gradient(z, [w1, w2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A non-persistent GradientTape can only be used to compute one set of gradients (or jacobians)\n"
     ]
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)\n",
    "\n",
    "dz_dw1 = tape.gradient(z, w1)  # returns tensor 36.0\n",
    "try:\n",
    "    dz_dw2 = tape.gradient(z, w2)  # raises a RuntimeError!\n",
    "except RuntimeError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    z = f(w1, w2)\n",
    "\n",
    "dz_dw1 = tape.gradient(z, w1)  # returns tensor 36.0\n",
    "dz_dw2 = tape.gradient(z, w2)  # returns tensor 10.0, works fine now!\n",
    "del tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dz_dw1, dz_dw2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1, c2 = tf.constant(5.), tf.constant(3.)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(c1, c2)\n",
    "\n",
    "gradients = tape.gradient(z, [c1, c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(c1)\n",
    "    tape.watch(c2)\n",
    "    z = f(c1, c2)\n",
    "\n",
    "gradients = tape.gradient(z, [c1, c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=136.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=30.0>]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – if given a vector, tape.gradient() will compute the gradient of\n",
    "#              the vector's sum.\n",
    "with tf.GradientTape() as tape:\n",
    "    z1 = f(w1, w2 + 2.)\n",
    "    z2 = f(w1, w2 + 5.)\n",
    "    z3 = f(w1, w2 + 7.)\n",
    "\n",
    "tape.gradient([z1, z2, z3], [w1, w2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=136.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=30.0>]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – shows that we get the same result as the previous cell\n",
    "with tf.GradientTape() as tape:\n",
    "    z1 = f(w1, w2 + 2.)\n",
    "    z2 = f(w1, w2 + 5.)\n",
    "    z3 = f(w1, w2 + 7.)\n",
    "    z = z1 + z2 + z3\n",
    "\n",
    "tape.gradient(z, [w1, w2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra code – shows how to compute the jacobians and the hessians\n",
    "with tf.GradientTape(persistent=True) as hessian_tape:\n",
    "    with tf.GradientTape() as jacobian_tape:\n",
    "        z = f(w1, w2)\n",
    "    jacobians = jacobian_tape.gradient(z, [w1, w2])\n",
    "hessians = [hessian_tape.gradient(jacobian, [w1, w2])\n",
    "            for jacobian in jacobians]\n",
    "del hessian_tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[<tf.Tensor: shape=(), dtype=float32, numpy=6.0>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=2.0>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=2.0>, None]]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hessians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(w1, w2):\n",
    "    return 3 * w1 ** 2 + tf.stop_gradient(2 * w1 * w2)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)  # same result as without stop_gradient()\n",
    "\n",
    "gradients = tape.gradient(z, [w1, w2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=30.0>, None]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=inf>]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable(1e-50)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = tf.sqrt(x)\n",
    "\n",
    "tape.gradient(z, [x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=30.0>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.log(tf.exp(tf.constant(30., dtype=tf.float32)) + 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(1,), dtype=float32, numpy=array([nan], dtype=float32)>]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable([1.0e30])\n",
    "with tf.GradientTape() as tape:\n",
    "    z = my_softplus(x)\n",
    "\n",
    "tape.gradient(z, [x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_softplus(z):\n",
    "    return tf.math.log(1 + tf.exp(-tf.abs(z))) + tf.maximum(0., z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the proof that this equation is equal to log(1 + exp(_z_)):\n",
    "* softplus(_z_) = log(1 + exp(_z_))\n",
    "* softplus(_z_) = log(1 + exp(_z_)) - log(exp(_z_)) + log(exp(_z_)) ; **just adding and subtracting the same value**\n",
    "* softplus(_z_) = log\\[(1 + exp(_z_)) / exp(_z_)\\] + log(exp(_z_)) ; **since log(_a_) - log(_b_) = log(_a_ / _b_)**\n",
    "* softplus(_z_) = log\\[(1 + exp(_z_)) / exp(_z_)\\] + _z_ ; **since log(exp(_z_)) = _z_**\n",
    "* softplus(_z_) = log\\[1 / exp(_z_) + exp(_z_) / exp(_z_)\\] + _z_ ; **since (1 + _a_) / _b_ = 1 / _b_ + _a_ / _b_**\n",
    "* softplus(_z_) = log\\[exp(–_z_) + 1\\] + _z_ ; **since 1 / exp(_z_) = exp(–z), and exp(_z_) / exp(_z_) = 1**\n",
    "* softplus(_z_) = softplus(–_z_) + _z_ ; **we recognize the definition at the top, but with –_z_**\n",
    "* softplus(_z_) = softplus(–|_z_|) + max(0, _z_) ; **if you consider both cases, _z_ < 0 or _z_ ≥ 0, you will see that this works**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.custom_gradient\n",
    "def my_softplus(z):\n",
    "    def my_softplus_gradients(grads):  # grads = backprop'ed from upper layers\n",
    "        return grads * (1 - 1 / (1 + tf.exp(z)))  # stable grads of softplus\n",
    "\n",
    "    result = tf.math.log(1 + tf.exp(-tf.abs(z))) + tf.maximum(0., z)\n",
    "    return result, my_softplus_gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1000.], dtype=float32)>,\n",
       " [<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – shows that the function is now stable, as well as its gradients\n",
    "x = tf.Variable([1000.])\n",
    "with tf.GradientTape() as tape:\n",
    "    z = my_softplus(x)\n",
    "\n",
    "z, tape.gradient(z, [x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Training Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.set_random_seed(42)  # extra code – to ensure reproducibility\n",
    "l2_reg = tf.keras.regularizers.l2(0.05)\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(30, activation=\"relu\", kernel_initializer=\"he_normal\",\n",
    "                          kernel_regularizer=l2_reg),\n",
    "    tf.keras.layers.Dense(1, kernel_regularizer=l2_reg)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch(X, y, batch_size=32):\n",
    "    idx = np.random.randint(len(X), size=batch_size)\n",
    "    return X[idx], y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_status_bar(step, total, loss, metrics=None):\n",
    "    metrics = \" - \".join([f\"{m.name}: {m.result():.4f}\"\n",
    "                          for m in [loss] + (metrics or [])])\n",
    "    end = \"\" if step < total else \"\\n\"\n",
    "    print(f\"\\r{step}/{total} - \" + metrics, end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning**: the `tf.keras.losses.mean_squared_error()` function not longer exists, you must use `tf.keras.losses.MeanSquaredError` class instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 32\n",
    "n_steps = len(X_train) // batch_size\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "mean_loss = tf.keras.metrics.Mean()\n",
    "metrics = [tf.keras.metrics.MeanAbsoluteError()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "362/362 - mean: 3.5419 - mean_absolute_error: 0.6640\n",
      "Epoch 2/5\n",
      "362/362 - mean: 1.8693 - mean_absolute_error: 0.5431\n",
      "Epoch 3/5\n",
      "362/362 - mean: 1.1428 - mean_absolute_error: 0.5030\n",
      "Epoch 4/5\n",
      "362/362 - mean: 0.8501 - mean_absolute_error: 0.4977\n",
      "Epoch 5/5\n",
      "362/362 - mean: 0.7280 - mean_absolute_error: 0.5014\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "    print(f\"Epoch {epoch}/{n_epochs}\")\n",
    "    for step in range(1, n_steps + 1):\n",
    "        X_batch, y_batch = random_batch(X_train_scaled, y_train)\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(X_batch, training=True)\n",
    "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "            loss = tf.add_n([main_loss] + model.losses)\n",
    "\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "        # extra code – if your model has variable constraints\n",
    "        for variable in model.variables:\n",
    "            if variable.constraint is not None:\n",
    "                variable.assign(variable.constraint(variable))\n",
    "\n",
    "        mean_loss(loss)\n",
    "        for metric in metrics:\n",
    "            metric(y_batch, y_pred)\n",
    "\n",
    "        print_status_bar(step, n_steps, mean_loss, metrics)\n",
    "\n",
    "    for metric in [mean_loss] + metrics:\n",
    "        metric.reset_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4c392c1baf9489e9b76d059e57874f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "All epochs:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70598cb6964740248e8aae8cfe3ea42b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/5:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b6724331300470ba5783f8c40114552",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/5:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f228afeb5a747999db1a006ac88aad7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/5:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bbc933b17d4416baf0f4f2f9c115509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/5:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21c4879c3c304d00b22bf5ee30c579f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/5:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# extra code – shows how to use the tqdm package to display nice progress bars\n",
    "\n",
    "from tqdm.notebook import trange\n",
    "from collections import OrderedDict\n",
    "with trange(1, n_epochs + 1, desc=\"All epochs\") as epochs:\n",
    "    for epoch in epochs:\n",
    "        with trange(1, n_steps + 1, desc=f\"Epoch {epoch}/{n_epochs}\") as steps:\n",
    "            for step in steps:\n",
    "                X_batch, y_batch = random_batch(X_train_scaled, y_train)\n",
    "                with tf.GradientTape() as tape:\n",
    "                    y_pred = model(X_batch)\n",
    "                    main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "                    loss = tf.add_n([main_loss] + model.losses)\n",
    "\n",
    "                gradients = tape.gradient(loss, model.trainable_variables)\n",
    "                optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "                for variable in model.variables:\n",
    "                    if variable.constraint is not None:\n",
    "                        variable.assign(variable.constraint(variable))\n",
    "\n",
    "                status = OrderedDict()\n",
    "                mean_loss(loss)\n",
    "                status[\"loss\"] = mean_loss.result().numpy()\n",
    "                for metric in metrics:\n",
    "                    metric(y_batch, y_pred)\n",
    "                    status[metric.name] = metric.result().numpy()\n",
    "\n",
    "                steps.set_postfix(status)\n",
    "\n",
    "        for metric in [mean_loss] + metrics:\n",
    "            metric.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cube(x):\n",
    "    return x ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.polymorphic_function.polymorphic_function.Function at 0x1e396463ce0>"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube = tf.function(cube)\n",
    "tf_cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=8>"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def tf_cube(x):\n",
    "    return x ** 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** the rest of the code in this section is in appendix D."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF Functions and Concrete Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ConcreteFunction (x: TensorSpec(shape=(), dtype=tf.float32, name=None)) -> TensorSpec(shape=(), dtype=tf.float32, name=None) at 0x1E38FE4BE60>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function = tf_cube.get_concrete_function(tf.constant(2.0))\n",
    "concrete_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function is tf_cube.get_concrete_function(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Function Definitions and Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.func_graph.FuncGraph at 0x1e39647b340>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'x' type=Placeholder>,\n",
       " <tf.Operation 'pow/y' type=Const>,\n",
       " <tf.Operation 'pow' type=Pow>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ops = concrete_function.graph.get_operations()\n",
    "ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'x:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'pow/y:0' shape=() dtype=float32>]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pow_op = ops[2]\n",
    "list(pow_op.inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'pow:0' shape=() dtype=float32>]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pow_op.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Operation 'x' type=Placeholder>"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function.graph.get_operation_by_name('x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Identity:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function.graph.get_tensor_by_name('Identity:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"__inference_tf_cube_672151\"\n",
       "input_arg {\n",
       "  name: \"x\"\n",
       "  type: DT_FLOAT\n",
       "}\n",
       "output_arg {\n",
       "  name: \"identity\"\n",
       "  type: DT_FLOAT\n",
       "}"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function.function_def.signature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How TF Functions Trace Python Functions to Extract Their Computation Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def tf_cube(x):\n",
    "    print(f\"x = {x}\")\n",
    "    return x ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = Tensor(\"x:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "result = tf_cube(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = 2\n"
     ]
    }
   ],
   "source": [
    "result = tf_cube(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = 3\n"
     ]
    }
   ],
   "source": [
    "result = tf_cube(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = Tensor(\"x:0\", shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "result = tf_cube(tf.constant([[1., 2.]]))  # New shape: trace!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = Tensor(\"x:0\", shape=(2, 2), dtype=float32)\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function tf_cube at 0x000001E39644AAC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "result = tf_cube(tf.constant([[3., 4.], [5., 6.]]))  # New shape: trace!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = tf_cube(tf.constant([[7., 8.], [9., 10.]]))  # Same shape: no trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to specify a particular input signature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(input_signature=[tf.TensorSpec([None, 28, 28], tf.float32)])\n",
    "def shrink(images):\n",
    "    print(\"Tracing\", images)  # extra code to show when tracing happens\n",
    "    return images[:, ::2, ::2] # drop half the rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing Tensor(\"images:0\", shape=(None, 28, 28), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "img_batch_1 = tf.random.uniform(shape=[100, 28, 28])\n",
    "img_batch_2 = tf.random.uniform(shape=[50, 28, 28])\n",
    "preprocessed_images = shrink(img_batch_1)  # Works fine, traces the function\n",
    "preprocessed_images = shrink(img_batch_2)  # Works fine, same concrete function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binding inputs to tf.function failed due to `Can not cast TensorSpec(shape=(2, 2, 2), dtype=tf.float32, name=None) to TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name=None)`. Received args: (<tf.Tensor: shape=(2, 2, 2), dtype=float32, numpy=\n",
      "array([[[0.7413678 , 0.62854624],\n",
      "        [0.01738465, 0.3431449 ]],\n",
      "\n",
      "       [[0.51063764, 0.3777541 ],\n",
      "        [0.07321596, 0.02137029]]], dtype=float32)>,) and kwargs: {} for signature: (images: TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name=None)).\n"
     ]
    }
   ],
   "source": [
    "img_batch_3 = tf.random.uniform(shape=[2, 2, 2])\n",
    "try:\n",
    "    preprocessed_images = shrink(img_batch_3)  # TypeError! Incompatible inputs\n",
    "except TypeError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Autograph To Capture Control Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A \"static\" `for` loop using `range()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def add_10(x):\n",
    "    for i in range(10):\n",
    "        x += 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=15>"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10(tf.constant(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'x' type=Placeholder>,\n",
       " <tf.Operation 'add/y' type=Const>,\n",
       " <tf.Operation 'add' type=AddV2>,\n",
       " <tf.Operation 'add_1/y' type=Const>,\n",
       " <tf.Operation 'add_1' type=AddV2>,\n",
       " <tf.Operation 'add_2/y' type=Const>,\n",
       " <tf.Operation 'add_2' type=AddV2>,\n",
       " <tf.Operation 'add_3/y' type=Const>,\n",
       " <tf.Operation 'add_3' type=AddV2>,\n",
       " <tf.Operation 'add_4/y' type=Const>,\n",
       " <tf.Operation 'add_4' type=AddV2>,\n",
       " <tf.Operation 'add_5/y' type=Const>,\n",
       " <tf.Operation 'add_5' type=AddV2>,\n",
       " <tf.Operation 'add_6/y' type=Const>,\n",
       " <tf.Operation 'add_6' type=AddV2>,\n",
       " <tf.Operation 'add_7/y' type=Const>,\n",
       " <tf.Operation 'add_7' type=AddV2>,\n",
       " <tf.Operation 'add_8/y' type=Const>,\n",
       " <tf.Operation 'add_8' type=AddV2>,\n",
       " <tf.Operation 'add_9/y' type=Const>,\n",
       " <tf.Operation 'add_9' type=AddV2>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10.get_concrete_function(tf.constant(5)).graph.get_operations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A \"dynamic\" loop using `tf.while_loop()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra code – shows how to use tf.while_loop (usually @tf.function is simpler)\n",
    "@tf.function\n",
    "def add_10(x):\n",
    "    condition = lambda i, x: tf.less(i, 10)\n",
    "    body = lambda i, x: (tf.add(i, 1), tf.add(x, 1))\n",
    "    final_i, final_x = tf.while_loop(condition, body, [tf.constant(0), x])\n",
    "    return final_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=15>"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10(tf.constant(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'x' type=Placeholder>,\n",
       " <tf.Operation 'Const' type=Const>,\n",
       " <tf.Operation 'while/maximum_iterations' type=Const>,\n",
       " <tf.Operation 'while/loop_counter' type=Const>,\n",
       " <tf.Operation 'while' type=StatelessWhile>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10.get_concrete_function(tf.constant(5)).graph.get_operations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A \"dynamic\" `for` loop using `tf.range()` (captured by autograph):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def add_10(x):\n",
    "    for i in tf.range(10):\n",
    "        x = x + 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'x' type=Placeholder>,\n",
       " <tf.Operation 'range/start' type=Const>,\n",
       " <tf.Operation 'range/limit' type=Const>,\n",
       " <tf.Operation 'range/delta' type=Const>,\n",
       " <tf.Operation 'range' type=Range>,\n",
       " <tf.Operation 'sub' type=Sub>,\n",
       " <tf.Operation 'floordiv' type=FloorDiv>,\n",
       " <tf.Operation 'mod' type=FloorMod>,\n",
       " <tf.Operation 'zeros_like' type=Const>,\n",
       " <tf.Operation 'NotEqual' type=NotEqual>,\n",
       " <tf.Operation 'Cast' type=Cast>,\n",
       " <tf.Operation 'add' type=AddV2>,\n",
       " <tf.Operation 'zeros_like_1' type=Const>,\n",
       " <tf.Operation 'Maximum' type=Maximum>,\n",
       " <tf.Operation 'while/maximum_iterations' type=Const>,\n",
       " <tf.Operation 'while/loop_counter' type=Const>,\n",
       " <tf.Operation 'while' type=StatelessWhile>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10.get_concrete_function(tf.constant(0)).graph.get_operations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Variables and Other Resources in TF Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=2>"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = tf.Variable(0)\n",
    "\n",
    "@tf.function\n",
    "def increment(counter, c=1):\n",
    "    return counter.assign_add(c)\n",
    "\n",
    "increment(counter)  # counter is now equal to 1\n",
    "increment(counter)  # counter is now equal to 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"counter\"\n",
       "type: DT_RESOURCE"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_def = increment.get_concrete_function(counter).function_def\n",
    "function_def.signature.input_arg[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = tf.Variable(0)\n",
    "\n",
    "@tf.function\n",
    "def increment(c=1):\n",
    "    return counter.assign_add(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=2>"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "increment()\n",
    "increment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"assignaddvariableop_resource\"\n",
       "type: DT_RESOURCE"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_def = increment.get_concrete_function().function_def\n",
    "function_def.signature.input_arg[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Counter:\n",
    "    def __init__(self):\n",
    "        self.counter = tf.Variable(0)\n",
    "\n",
    "    @tf.function\n",
    "    def increment(self, c=1):\n",
    "        return self.counter.assign_add(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=2>"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = Counter()\n",
    "c.increment()\n",
    "c.increment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def tf__add(x):\n",
      "    with ag__.FunctionScope('add_10', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
      "        do_return = False\n",
      "        retval_ = ag__.UndefinedReturnValue()\n",
      "\n",
      "        def get_state():\n",
      "            return (x,)\n",
      "\n",
      "        def set_state(vars_):\n",
      "            nonlocal x\n",
      "            x, = vars_\n",
      "\n",
      "        def loop_body(itr):\n",
      "            nonlocal x\n",
      "            i = itr\n",
      "            x = ag__.ld(x)\n",
      "            x += 1\n",
      "        i = ag__.Undefined('i')\n",
      "        ag__.for_stmt(ag__.converted_call(ag__.ld(tf).range, (10,), None, fscope), None, loop_body, get_state, set_state, ('x',), {'iterate_names': 'i'})\n",
      "        try:\n",
      "            do_return = True\n",
      "            retval_ = ag__.ld(x)\n",
      "        except:\n",
      "            do_return = False\n",
      "            raise\n",
      "        return fscope.ret(retval_, do_return)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def add_10(x):\n",
    "    for i in tf.range(10):\n",
    "        x += 1\n",
    "    return x\n",
    "\n",
    "print(tf.autograph.to_code(add_10.python_function))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra code – shows how to display the autograph code with syntax highlighting\n",
    "def display_tf_code(func):\n",
    "    from IPython.display import display, Markdown\n",
    "    if hasattr(func, \"python_function\"):\n",
    "        func = func.python_function\n",
    "    code = tf.autograph.to_code(func)\n",
    "    display(Markdown(f'```python\\n{code}\\n```'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "def tf__add(x):\n",
       "    with ag__.FunctionScope('add_10', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
       "        do_return = False\n",
       "        retval_ = ag__.UndefinedReturnValue()\n",
       "\n",
       "        def get_state():\n",
       "            return (x,)\n",
       "\n",
       "        def set_state(vars_):\n",
       "            nonlocal x\n",
       "            x, = vars_\n",
       "\n",
       "        def loop_body(itr):\n",
       "            nonlocal x\n",
       "            i = itr\n",
       "            x = ag__.ld(x)\n",
       "            x += 1\n",
       "        i = ag__.Undefined('i')\n",
       "        ag__.for_stmt(ag__.converted_call(ag__.ld(tf).range, (10,), None, fscope), None, loop_body, get_state, set_state, ('x',), {'iterate_names': 'i'})\n",
       "        try:\n",
       "            do_return = True\n",
       "            retval_ = ag__.ld(x)\n",
       "        except:\n",
       "            do_return = False\n",
       "            raise\n",
       "        return fscope.ret(retval_, do_return)\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_tf_code(add_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using TF Functions with tf.keras (or Not)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, tf.keras will automatically convert your custom code into TF Functions, no need to use\n",
    "`tf.function()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom loss function\n",
    "def my_mse(y_true, y_pred):\n",
    "    print(\"Tracing loss my_mse()\")\n",
    "    return tf.reduce_mean(tf.square(y_pred - y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom metric function\n",
    "def my_mae(y_true, y_pred):\n",
    "    print(\"Tracing metric my_mae()\")\n",
    "    return tf.reduce_mean(tf.abs(y_pred - y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom layer\n",
    "class MyDense(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, activation=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(name='kernel', \n",
    "                                      shape=(input_shape[1], self.units),\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    "        self.biases = self.add_weight(name='bias', \n",
    "                                      shape=(self.units,),\n",
    "                                      initializer='zeros',\n",
    "                                      trainable=True)\n",
    "\n",
    "    def call(self, X):\n",
    "        print(\"Tracing MyDense.call()\")\n",
    "        return self.activation(X @ self.kernel + self.biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom model\n",
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = MyDense(30, activation=\"relu\")\n",
    "        self.hidden2 = MyDense(30, activation=\"relu\")\n",
    "        self.output_ = MyDense(1)\n",
    "\n",
    "    def call(self, input):\n",
    "        print(\"Tracing MyModel.call()\")\n",
    "        hidden1 = self.hidden1(input)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = tf.keras.layers.concatenate([input, hidden2])\n",
    "        output = self.output_(concat)\n",
    "        return output\n",
    "\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=my_mse, optimizer=\"nadam\", metrics=[my_mae])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "\u001b[1m329/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.1103 - my_mae: 1.3471Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 2.9521 - my_mae: 1.2979 - val_loss: 0.4396 - val_my_mae: 0.4727\n",
      "Epoch 2/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4711 - my_mae: 0.4937 - val_loss: 0.4665 - val_my_mae: 0.4480\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - loss: 0.4162 - my_mae: 0.4560\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.41415703296661377, 0.4553782045841217]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can turn this off by creating the model with `dynamic=True` (or calling `super().__init__(dynamic=True, **kwargs)` in the model's constructor):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning**: the `dynamic` argument no longer exists since Keras 3. However, you can still compile a model with `run_eagerly=True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=my_mse, optimizer=\"nadam\", metrics=[my_mae], run_eagerly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.545090198516846, 2.0603599548339844]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled[:64], y_train[:64], epochs=1,\n",
    "          validation_data=(X_valid_scaled[:64], y_valid[:64]), verbose=0)\n",
    "model.evaluate(X_test_scaled[:64], y_test[:64], verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Material – Custom Optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Keras API to create a custom optimizer has changed since Keras 3, so if you need to create one, I recommend you draw inspiration from the source code of one of Keras's builtin optimizers, such as [SGD](https://github.com/keras-team/keras/blob/b083f2e95d4d6b09f6ec22717fd1becccbdbcec1/keras/src/optimizers/sgd.py#L7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. to 11."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. TensorFlow is an open-source library for numerical computation, particularly well suited and fine-tuned for large-scale Machine Learning. Its core is similar to NumPy, but it also features GPU support, support for distributed computing, computation graph analysis and optimization capabilities (with a portable graph format that allows you to train a TensorFlow model in one environment and run it in another), an optimization API based on reverse-mode autodiff, and several powerful APIs such as tf.keras, tf.data, tf.image, tf.signal, and more. Other popular Deep Learning libraries include PyTorch, MXNet, Microsoft Cognitive Toolkit, Theano, Caffe2, and Chainer.\n",
    "2. Although TensorFlow offers most of the functionalities provided by NumPy, it is not a drop-in replacement, for a few reasons. First, the names of the functions are not always the same (for example, `tf.reduce_sum()` versus `np.sum()`). Second, some functions do not behave in exactly the same way (for example, `tf.transpose()` creates a transposed copy of a tensor, while NumPy's `T` attribute creates a transposed view, without actually copying any data). Lastly, NumPy arrays are mutable, while TensorFlow tensors are not (but you can use a `tf.Variable` if you need a mutable object).\n",
    "3. Both `tf.range(10)` and `tf.constant(np.arange(10))` return a one-dimensional tensor containing the integers 0 to 9. However, the former uses 32-bit integers while the latter uses 64-bit integers. Indeed, TensorFlow defaults to 32 bits, while NumPy defaults to 64 bits.\n",
    "4. Beyond regular tensors, TensorFlow offers several other data structures, including sparse tensors, tensor arrays, ragged tensors, queues, string tensors, and sets. The last two are actually represented as regular tensors, but TensorFlow provides special functions to manipulate them (in `tf.strings` and `tf.sets`).\n",
    "5. When you want to define a custom loss function, in general you can just implement it as a regular Python function. However, if your custom loss function must support some hyperparameters (or any other state), then you should subclass the `keras.losses.Loss` class and implement the `__init__()` and `call()` methods. If you want the loss function's hyperparameters to be saved along with the model, then you must also implement the `get_config()` method.\n",
    "6. Much like custom loss functions, most metrics can be defined as regular Python functions. But if you want your custom metric to support some hyperparameters (or any other state), then you should subclass the `keras.metrics.Metric` class. Moreover, if computing the metric over a whole epoch is not equivalent to computing the mean metric over all batches in that epoch (e.g., as for the precision and recall metrics), then you should subclass the `keras.metrics.Metric` class and implement the `__init__()`, `update_state()`, and `result()` methods to keep track of a running metric during each epoch. You should also implement the `reset_state()` method unless all it needs to do is reset all variables to 0.0. If you want the state to be saved along with the model, then you should implement the `get_config()` method as well.\n",
    "7. You should distinguish the internal components of your model (i.e., layers or reusable blocks of layers) from the model itself (i.e., the object you will train). The former should subclass the `keras.layers.Layer` class, while the latter should subclass the `keras.models.Model` class.\n",
    "8. Writing your own custom training loop is fairly advanced, so you should only do it if you really need to. Keras provides several tools to customize training without having to write a custom training loop: callbacks, custom regularizers, custom constraints, custom losses, and so on. You should use these instead of writing a custom training loop whenever possible: writing a custom training loop is more error-prone, and it will be harder to reuse the custom code you write. However, in some cases writing a custom training loop is necessary⁠—for example, if you want to use different optimizers for different parts of your neural network, like in the [Wide & Deep paper](https://homl.info/widedeep). A custom training loop can also be useful when debugging, or when trying to understand exactly how training works.\n",
    "9. Custom Keras components should be convertible to TF Functions, which means they should stick to TF operations as much as possible and respect all the rules listed in Chapter 12 (in the _TF Function Rules_ section). If you absolutely need to include arbitrary Python code in a custom component, you can either wrap it in a `tf.py_function()` operation (but this will reduce performance and limit your model's portability) or set `dynamic=True` when creating the custom layer or model (or set `run_eagerly=True` when calling the model's `compile()` method).\n",
    "10. Please refer to Chapter 12 for the list of rules to respect when creating a TF Function (in the _TF Function Rules_ section).\n",
    "11. Creating a dynamic Keras model can be useful for debugging, as it will not compile any custom component to a TF Function, and you can use any Python debugger to debug your code. It can also be useful if you want to include arbitrary Python code in your model (or in your training code), including calls to external libraries. To make a model dynamic, you must set `dynamic=True` when creating it. Alternatively, you can set `run_eagerly=True` when calling the model's `compile()` method. Making a model dynamic prevents Keras from using any of TensorFlow's graph features, so it will slow down training and inference, and you will not have the possibility to export the computation graph, which will limit your model's portability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Implement a custom layer that performs _Layer Normalization_\n",
    "_We will use this type of layer in Chapter 15 when using Recurrent Neural Networks._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a.\n",
    "_Exercise: The `build()` method should define two trainable weights *α* and *β*, both of shape `input_shape[-1:]` and data type `tf.float32`. *α* should be initialized with 1s, and *β* with 0s._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution: see below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b.\n",
    "_Exercise: The `call()` method should compute the mean_ μ _and standard deviation_ σ _of each instance's features. For this, you can use `tf.nn.moments(inputs, axes=-1, keepdims=True)`, which returns the mean μ and the variance σ<sup>2</sup> of all instances (compute the square root of the variance to get the standard deviation). Then the function should compute and return *α*⊗(*X* - μ)/(σ + ε) + *β*, where ⊗ represents itemwise multiplication (`*`) and ε is a smoothing term (small constant to avoid division by zero, e.g., 0.001)._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNormalization(tf.keras.layers.Layer):\n",
    "    def __init__(self, eps=0.001, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.eps = eps\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        self.alpha = self.add_weight(\n",
    "            name=\"alpha\", shape=batch_input_shape[-1:],\n",
    "            initializer=\"ones\")\n",
    "        self.beta = self.add_weight(\n",
    "            name=\"beta\", shape=batch_input_shape[-1:],\n",
    "            initializer=\"zeros\")\n",
    "\n",
    "    def call(self, X):\n",
    "        mean, variance = tf.nn.moments(X, axes=-1, keepdims=True)\n",
    "        return self.alpha * (X - mean) / (tf.sqrt(variance + self.eps)) + self.beta\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"eps\": self.eps}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that making _ε_ a hyperparameter (`eps`) was not compulsory. Also note that it's preferable to compute `tf.sqrt(variance + self.eps)` rather than `tf.sqrt(variance) + self.eps`. Indeed, the derivative of sqrt(z) is undefined when z=0, so training will bomb whenever the variance vector has at least one component equal to 0. Adding _ε_ within the square root guarantees that this will never happen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c.\n",
    "_Exercise: Ensure that your custom layer produces the same (or very nearly the same) output as the `tf.keras.layers.LayerNormalization` layer._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create one instance of each class, apply them to some data (e.g., the training set), and ensure that the difference is negligeable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning**: the `mean_absolute_error()` function no longer exists. Instead, you must use the `MeanAbsoluteError` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=2.99457e-08>"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X_train.astype(np.float32)\n",
    "\n",
    "custom_layer_norm = LayerNormalization()\n",
    "keras_layer_norm = tf.keras.layers.LayerNormalization()\n",
    "\n",
    "tf.reduce_mean(tf.keras.losses.MeanAbsoluteError()(\n",
    "    keras_layer_norm(X), custom_layer_norm(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yep, that's close enough. To be extra sure, let's make alpha and beta completely random and compare again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1.6172255e-08>"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(42)\n",
    "random_alpha = np.random.rand(X.shape[-1])\n",
    "random_beta = np.random.rand(X.shape[-1])\n",
    "\n",
    "custom_layer_norm.set_weights([random_alpha, random_beta])\n",
    "keras_layer_norm.set_weights([random_alpha, random_beta])\n",
    "\n",
    "tf.reduce_mean(tf.keras.losses.MeanAbsoluteError()(\n",
    "    keras_layer_norm(X), custom_layer_norm(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still a negligeable difference! Our custom layer works fine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Train a model using a custom training loop to tackle the Fashion MNIST dataset\n",
    "_The Fashion MNIST dataset was introduced in Chapter 10._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a.\n",
    "_Exercise: Display the epoch, iteration, mean training loss, and mean accuracy over each epoch (updated at each iteration), as well as the validation loss and accuracy at the end of each epoch._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "X_train_full = X_train_full.astype(np.float32) / 255.\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test.astype(np.float32) / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Devon Tamaam Adira S\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 32\n",
    "n_steps = len(X_train) // batch_size\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=0.01)\n",
    "loss_fn = tf.keras.losses.sparse_categorical_crossentropy\n",
    "mean_loss = tf.keras.metrics.Mean()\n",
    "metrics = [tf.keras.metrics.SparseCategoricalAccuracy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11b9739c0089462b951c15a2089c3717",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "All epochs:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93240c4b0cf941fe91bb3a7893fabaf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41a62ee6938741ff89ca0d61eebf9885",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9ef45c770894a84ae6b4a10405d0861",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fbd8367ee5b4627b52e2c403433e93d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b8cfa22ac5949778e2a749dc17292cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with trange(1, n_epochs + 1, desc=\"All epochs\") as epochs:\n",
    "    for epoch in epochs:\n",
    "        with trange(1, n_steps + 1, desc=f\"Epoch {epoch}/{n_epochs}\") as steps:\n",
    "            for step in steps:\n",
    "                X_batch, y_batch = random_batch(X_train, y_train)\n",
    "                with tf.GradientTape() as tape:\n",
    "                    y_pred = model(X_batch)\n",
    "                    main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "                    loss = tf.add_n([main_loss] + model.losses)\n",
    "                gradients = tape.gradient(loss, model.trainable_variables)\n",
    "                optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "                for variable in model.variables:\n",
    "                    if variable.constraint is not None:\n",
    "                        variable.assign(variable.constraint(variable))                    \n",
    "                status = OrderedDict()\n",
    "                mean_loss(loss)\n",
    "                status[\"loss\"] = mean_loss.result().numpy()\n",
    "                for metric in metrics:\n",
    "                    metric(y_batch, y_pred)\n",
    "                    status[metric.name] = metric.result().numpy()\n",
    "                steps.set_postfix(status)\n",
    "            y_pred = model(X_valid)\n",
    "            status[\"val_loss\"] = np.mean(loss_fn(y_valid, y_pred))\n",
    "            status[\"val_accuracy\"] = np.mean(tf.keras.metrics.sparse_categorical_accuracy(\n",
    "                tf.constant(y_valid, dtype=np.float32), y_pred))\n",
    "            steps.set_postfix(status)\n",
    "        for metric in [mean_loss] + metrics:\n",
    "            metric.reset_state()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b.\n",
    "_Exercise: Try using a different optimizer with a different learning rate for the upper layers and the lower layers._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_layers = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "])\n",
    "upper_layers = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\"),\n",
    "])\n",
    "model = tf.keras.Sequential([\n",
    "    lower_layers, upper_layers\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_optimizer = tf.keras.optimizers.SGD(learning_rate=1e-4)\n",
    "upper_optimizer = tf.keras.optimizers.Nadam(learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 32\n",
    "n_steps = len(X_train) // batch_size\n",
    "loss_fn = tf.keras.losses.sparse_categorical_crossentropy\n",
    "mean_loss = tf.keras.metrics.Mean()\n",
    "metrics = [tf.keras.metrics.SparseCategoricalAccuracy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5fda58585264663b71ef5ab73b17517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "All epochs:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "418de9588ca54da9ac6282123b200e45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da9c8baaa6a74c6b9deb8297da5f5e1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38fcfbfa6a1042838f13121dbe390130",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c871a86ac1a04119bc1322ff47b9e417",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e2181ffdf5a4a0ea79dabc041084c49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with trange(1, n_epochs + 1, desc=\"All epochs\") as epochs:\n",
    "    for epoch in epochs:\n",
    "        with trange(1, n_steps + 1, desc=f\"Epoch {epoch}/{n_epochs}\") as steps:\n",
    "            for step in steps:\n",
    "                X_batch, y_batch = random_batch(X_train, y_train)\n",
    "                with tf.GradientTape(persistent=True) as tape:\n",
    "                    y_pred = model(X_batch)\n",
    "                    main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "                    loss = tf.add_n([main_loss] + model.losses)\n",
    "                for layers, optimizer in ((lower_layers, lower_optimizer),\n",
    "                                          (upper_layers, upper_optimizer)):\n",
    "                    gradients = tape.gradient(loss, layers.trainable_variables)\n",
    "                    optimizer.apply_gradients(zip(gradients, layers.trainable_variables))\n",
    "                del tape\n",
    "                for variable in model.variables:\n",
    "                    if variable.constraint is not None:\n",
    "                        variable.assign(variable.constraint(variable))                    \n",
    "                status = OrderedDict()\n",
    "                mean_loss(loss)\n",
    "                status[\"loss\"] = mean_loss.result().numpy()\n",
    "                for metric in metrics:\n",
    "                    metric(y_batch, y_pred)\n",
    "                    status[metric.name] = metric.result().numpy()\n",
    "                steps.set_postfix(status)\n",
    "            y_pred = model(X_valid)\n",
    "            status[\"val_loss\"] = np.mean(loss_fn(y_valid, y_pred))\n",
    "            status[\"val_accuracy\"] = np.mean(tf.keras.metrics.sparse_categorical_accuracy(\n",
    "                tf.constant(y_valid, dtype=np.float32), y_pred))\n",
    "            steps.set_postfix(status)\n",
    "        for metric in [mean_loss] + metrics:\n",
    "            metric.reset_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
