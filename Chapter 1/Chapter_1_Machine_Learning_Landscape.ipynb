{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2be56952",
   "metadata": {},
   "source": [
    "# My Summary: Chapter 1 - The Machine Learning Landscape\n",
    "\n",
    "In this notebook, I'll summarize what I learned from Chapter 1 of \"Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow\" by Aur√©lien G√©ron. This is my personal study notes and understanding of the key concepts.\n",
    "\n",
    "## My Learning Goals:\n",
    "- Understanding what Machine Learning actually is\n",
    "- Different types of ML systems and when to use them\n",
    "- Common challenges I might face when working with ML\n",
    "- How to properly test and validate my models\n",
    "- Hands-on practice with real examples\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d442c5",
   "metadata": {},
   "source": [
    "## Setting Up My Environment\n",
    "\n",
    "First, I need to import all the libraries I'll be using for my machine learning experiments and examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0275752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm importing all the essential libraries I'll need for my ML journey\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Making my plots look nice\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ Great! All my libraries are ready to go!\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81b3e57",
   "metadata": {},
   "source": [
    "## My Understanding: What is Machine Learning?\n",
    "\n",
    "From what I learned, **Machine Learning** is basically teaching computers to learn patterns from data without explicitly programming every single rule. The book gives this formal definition: A computer program learns from experience E with respect to task T and performance measure P, if its performance on T improves with experience E.\n",
    "\n",
    "### Key Terms I Need to Remember:\n",
    "- **Algorithm**: The \"recipe\" or set of instructions for solving a problem\n",
    "- **Model**: What I get after training an algorithm on data  \n",
    "- **Training**: The process where I feed data to the algorithm so it can learn\n",
    "- **Prediction**: Using my trained model to make guesses about new, unseen data\n",
    "\n",
    "Let me create a simple example to understand this better:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c27f6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# My first ML example: Can I predict house prices based on their size?\n",
    "# I'll create some fake data to see how this works\n",
    "np.random.seed(42)\n",
    "house_sizes = np.random.normal(150, 50, 100)  # House sizes in square meters\n",
    "house_prices = house_sizes * 2000 + np.random.normal(0, 50000, 100)  # Prices with some noise\n",
    "\n",
    "# Let me visualize this relationship\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(house_sizes, house_prices, alpha=0.6, color='blue')\n",
    "plt.xlabel('House Size (sq meters)')\n",
    "plt.ylabel('House Price ($)')\n",
    "plt.title('My First ML Problem: Can Size Predict Price?')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"üìä I created {len(house_sizes)} fake house examples\")\n",
    "print(f\"Average house size: {house_sizes.mean():.1f} sq meters\")\n",
    "print(f\"Average house price: ${house_prices.mean():,.0f}\")\n",
    "print(\"I can see there's definitely a pattern here!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebe0ec3",
   "metadata": {},
   "source": [
    "## Types of ML Systems - My Classification Guide\n",
    "\n",
    "I learned that ML systems can be categorized in several ways. Here's how I understand them:\n",
    "\n",
    "### 1. **Supervised vs Unsupervised Learning**\n",
    "\n",
    "**Supervised Learning**: When I have the \"answers\" (labels) in my training data\n",
    "- **Classification**: Predicting categories - like \"Is this email spam or not?\" or \"Is this a cat or dog?\"\n",
    "- **Regression**: Predicting numbers - like house prices, stock values, or temperatures\n",
    "\n",
    "**Unsupervised Learning**: When I don't have labels and need to find hidden patterns\n",
    "- **Clustering**: Grouping similar things together (like customer segments)\n",
    "- **Dimensionality Reduction**: Simplifying complex data while keeping the important stuff\n",
    "\n",
    "### 2. **Batch vs Online Learning**\n",
    "\n",
    "**Batch Learning**: I train my model once using all available data (like studying for an exam with all materials at once)\n",
    "**Online Learning**: My model learns continuously as new data comes in (like learning from daily experiences)\n",
    "\n",
    "### 3. **Instance-based vs Model-based Learning**\n",
    "\n",
    "**Instance-based**: Making predictions by comparing to similar examples I've seen before\n",
    "**Model-based**: Creating a mathematical model that captures the patterns in my data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593e5f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let me try this with a real dataset: the famous Iris dataset\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Loading the iris dataset that everyone talks about in ML\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "print(\"üå∏ EXPLORING THE IRIS DATASET\")\n",
    "print(f\"Data shape: {X.shape}\")\n",
    "print(f\"What we're measuring: {iris.feature_names}\")\n",
    "print(f\"Flower types: {iris.target_names}\")\n",
    "print(f\"Let me see what this data looks like:\")\n",
    "print(pd.DataFrame(X[:5], columns=iris.feature_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c4da8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# My First Supervised Learning Example: Classification\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# I'll split my data into training and testing parts\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Time to train my first classifier!\n",
    "my_classifier = DecisionTreeClassifier(random_state=42)\n",
    "my_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Let's see how well it does on new data\n",
    "y_pred = my_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"üéØ MY FIRST CLASSIFICATION RESULTS\")\n",
    "print(f\"My model got {accuracy:.1%} accuracy - not bad for my first try!\")\n",
    "print(\"\\nDetailed results:\")\n",
    "print(classification_report(y_test, y_pred, target_names=iris.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a733816a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# My First Unsupervised Learning Example: Clustering\n",
    "# What if I pretend I don't know the flower types and try to discover them?\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "my_clusters = kmeans.fit_predict(X)\n",
    "\n",
    "print(\"üîç MY FIRST CLUSTERING EXPERIMENT\")\n",
    "print(\"The algorithm found these cluster centers:\")\n",
    "print(pd.DataFrame(kmeans.cluster_centers_, columns=iris.feature_names))\n",
    "\n",
    "# Let me visualize how well my clustering worked\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# The real answer (what I'm trying to find)\n",
    "scatter1 = ax1.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis', alpha=0.7)\n",
    "ax1.set_xlabel('Sepal Length')\n",
    "ax1.set_ylabel('Sepal Width')\n",
    "ax1.set_title('The Real Flower Types (what I want to discover)')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# What my algorithm found\n",
    "scatter2 = ax2.scatter(X[:, 0], X[:, 1], c=my_clusters, cmap='viridis', alpha=0.7)\n",
    "ax2.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], \n",
    "           c='red', marker='x', s=200, linewidths=3, label='My Cluster Centers')\n",
    "ax2.set_xlabel('Sepal Length')\n",
    "ax2.set_ylabel('Sepal Width')\n",
    "ax2.set_title('What My Clustering Algorithm Found')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"Pretty cool! The algorithm found groups that are quite similar to the real flower types!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410b3dce",
   "metadata": {},
   "source": [
    "## Trying Regression: Predicting House Prices\n",
    "\n",
    "Now let me try a regression problem using real housing data. This should be more challenging than my simple example earlier!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1456fbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading real housing data from California\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "# Getting the dataset\n",
    "housing = fetch_california_housing()\n",
    "X_housing, y_housing = housing.data, housing.target\n",
    "\n",
    "# Making it easier to work with\n",
    "housing_df = pd.DataFrame(X_housing, columns=housing.feature_names)\n",
    "housing_df['target'] = y_housing\n",
    "\n",
    "print(\"üè† CALIFORNIA HOUSING DATA - THIS IS REAL!\")\n",
    "print(f\"Data size: {housing_df.shape}\")\n",
    "print(f\"What affects house prices: {list(housing.feature_names)}\")\n",
    "print(\"\\nWhat this data looks like:\")\n",
    "print(housing_df.head())\n",
    "\n",
    "print(f\"\\nCool facts about this dataset:\")\n",
    "print(f\"- {len(housing_df)} different housing areas in California\")\n",
    "print(f\"- I'm trying to predict: Median house value\")\n",
    "print(f\"- Average house value: ${y_housing.mean()*100000:,.0f}\")\n",
    "print(\"This is way more complex than my fake data from earlier!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620f14c2",
   "metadata": {},
   "source": [
    "## Getting My Data Ready\n",
    "\n",
    "Before I can train any models, I need to clean and prepare my data. This is probably one of the most important steps!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416e84a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let me explore and clean my data first\n",
    "print(\"üîß GETTING TO KNOW MY DATA\")\n",
    "\n",
    "# Are there any missing values I need to worry about?\n",
    "print(\"Checking for missing values:\")\n",
    "print(housing_df.isnull().sum())\n",
    "\n",
    "# What do the numbers look like?\n",
    "print(\"\\nüìä BASIC DATA OVERVIEW:\")\n",
    "print(housing_df.describe())\n",
    "\n",
    "# Let me visualize what I'm working with\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, column in enumerate(housing.feature_names):\n",
    "    axes[idx].hist(housing_df[column], bins=30, alpha=0.7)\n",
    "    axes[idx].set_title(f'{column}')\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Time to split my data properly (this is crucial!)\n",
    "X_train_housing, X_test_housing, y_train_housing, y_test_housing = train_test_split(\n",
    "    X_housing, y_housing, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÇÔ∏è MY DATA SPLIT:\")\n",
    "print(f\"Training set: {X_train_housing.shape[0]} samples (I'll learn from these)\")\n",
    "print(f\"Test set: {X_test_housing.shape[0]} samples (I'll test my model on these)\")\n",
    "print(\"Good practice: Never let my model see the test data during training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83484b61",
   "metadata": {},
   "source": [
    "## Creating Better Features\n",
    "\n",
    "I learned that sometimes I can create new, more useful features from existing ones. Let me try this feature engineering stuff!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743fb7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# My feature engineering experiment\n",
    "print(\"‚öôÔ∏è CREATING BETTER FEATURES\")\n",
    "\n",
    "# Let me make a copy so I don't mess up my original data\n",
    "housing_df_eng = housing_df.copy()\n",
    "\n",
    "# I'll create some features that might make more sense\n",
    "# How many rooms per household?\n",
    "housing_df_eng['rooms_per_household'] = housing_df_eng['AveRooms'] / housing_df_eng['AveOccup']\n",
    "\n",
    "# What's the bedroom to room ratio?\n",
    "housing_df_eng['bedrooms_per_room'] = housing_df_eng['AveBedrms'] / housing_df_eng['AveRooms']\n",
    "\n",
    "# How crowded are the households?\n",
    "housing_df_eng['population_per_household'] = housing_df_eng['Population'] / housing_df_eng['Households']\n",
    "\n",
    "print(\"I created these new features:\")\n",
    "print(\"- rooms_per_household (might indicate house size)\")\n",
    "print(\"- bedrooms_per_room (might indicate house type)\") \n",
    "print(\"- population_per_household (might indicate crowding)\")\n",
    "\n",
    "# Let me see which features correlate best with house prices\n",
    "new_features = ['rooms_per_household', 'bedrooms_per_room', 'population_per_household']\n",
    "correlations = housing_df_eng[new_features + ['target']].corr()['target'].sort_values(ascending=False)\n",
    "\n",
    "print(f\"\\nüìà HOW WELL DO MY NEW FEATURES CORRELATE WITH PRICES?\")\n",
    "for feature in new_features:\n",
    "    print(f\"{feature}: {correlations[feature]:.3f}\")\n",
    "\n",
    "# Now I need to scale everything (ML algorithms work better with scaled data)\n",
    "scaler = StandardScaler()\n",
    "feature_columns = list(housing.feature_names) + new_features\n",
    "\n",
    "# Preparing my enhanced dataset\n",
    "X_eng = housing_df_eng[feature_columns].values\n",
    "X_train_eng, X_test_eng, y_train_eng, y_test_eng = train_test_split(\n",
    "    X_eng, y_housing, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Scaling my features (this is important!)\n",
    "X_train_scaled = scaler.fit_transform(X_train_eng)\n",
    "X_test_scaled = scaler.transform(X_test_eng)\n",
    "\n",
    "print(f\"\\nüîß DATA PREPARATION COMPLETE\")\n",
    "print(f\"Started with: {len(housing.feature_names)} features\")\n",
    "print(f\"Now I have: {X_train_scaled.shape[1]} features\")\n",
    "print(\"All features are now properly scaled and ready for ML!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef03fa5",
   "metadata": {},
   "source": [
    "## Training My First Real ML Models\n",
    "\n",
    "Now for the exciting part! Let me train different algorithms and see which one works best for predicting house prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091cb1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time to train different ML algorithms and see which works best!\n",
    "print(\"ü§ñ MY MODEL TRAINING EXPERIMENT\")\n",
    "\n",
    "# I'll try these three different approaches\n",
    "my_models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Decision Tree': DecisionTreeRegressor(random_state=42),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# I'll keep track of how well each one does\n",
    "my_results = {}\n",
    "\n",
    "# Training each model and seeing how they perform\n",
    "for name, model in my_models.items():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Training my {name} model...\")\n",
    "    \n",
    "    # Training time!\n",
    "    model.fit(X_train_scaled, y_train_eng)\n",
    "    \n",
    "    # Let's see how well it learned\n",
    "    y_pred_train = model.predict(X_train_scaled)\n",
    "    y_pred_test = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculating how good (or bad) my predictions are\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train_eng, y_pred_train))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test_eng, y_pred_test))\n",
    "    train_r2 = r2_score(y_train_eng, y_pred_train)\n",
    "    test_r2 = r2_score(y_test_eng, y_pred_test)\n",
    "    \n",
    "    # Saving the results\n",
    "    my_results[name] = {\n",
    "        'train_rmse': train_rmse,\n",
    "        'test_rmse': test_rmse,\n",
    "        'train_r2': train_r2,\n",
    "        'test_r2': test_r2\n",
    "    }\n",
    "    \n",
    "    print(f\"Training error (RMSE): {train_rmse:.4f}\")\n",
    "    print(f\"Test error (RMSE): {test_rmse:.4f}\")\n",
    "    print(f\"Training accuracy (R¬≤): {train_r2:.4f}\")\n",
    "    print(f\"Test accuracy (R¬≤): {test_r2:.4f}\")\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"MY RESULTS SUMMARY:\")\n",
    "best_model = min(my_results.keys(), key=lambda x: my_results[x]['test_rmse'])\n",
    "print(f\"üèÜ My winner: {best_model}\")\n",
    "print(f\"Best test error (RMSE): {my_results[best_model]['test_rmse']:.4f}\")\n",
    "print(\"Lower RMSE = better predictions!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd0ca49",
   "metadata": {},
   "source": [
    "## Visualizing My Results\n",
    "\n",
    "Let me create some charts to better understand how my models performed. Visual analysis always helps me understand what's happening!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace94421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating visualizations to understand my results better\n",
    "print(\"üìä MY RESULTS VISUALIZATION\")\n",
    "\n",
    "# Setting up my comparison charts\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Chart 1: Comparing RMSE (error rates)\n",
    "model_names = list(my_results.keys())\n",
    "train_rmse_values = [my_results[name]['train_rmse'] for name in model_names]\n",
    "test_rmse_values = [my_results[name]['test_rmse'] for name in model_names]\n",
    "\n",
    "x = np.arange(len(model_names))\n",
    "width = 0.35\n",
    "\n",
    "axes[0, 0].bar(x - width/2, train_rmse_values, width, label='Training Error', alpha=0.8)\n",
    "axes[0, 0].bar(x + width/2, test_rmse_values, width, label='Test Error', alpha=0.8)\n",
    "axes[0, 0].set_xlabel('My Models')\n",
    "axes[0, 0].set_ylabel('RMSE (Lower = Better)')\n",
    "axes[0, 0].set_title('How Well Did My Models Do? (Error Comparison)')\n",
    "axes[0, 0].set_xticks(x)\n",
    "axes[0, 0].set_xticklabels(model_names, rotation=45)\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Chart 2: Comparing R¬≤ scores (accuracy)\n",
    "train_r2_values = [my_results[name]['train_r2'] for name in model_names]\n",
    "test_r2_values = [my_results[name]['test_r2'] for name in model_names]\n",
    "\n",
    "axes[0, 1].bar(x - width/2, train_r2_values, width, label='Training R¬≤', alpha=0.8)\n",
    "axes[0, 1].bar(x + width/2, test_r2_values, width, label='Test R¬≤', alpha=0.8)\n",
    "axes[0, 1].set_xlabel('My Models')\n",
    "axes[0, 1].set_ylabel('R¬≤ Score (Higher = Better)')\n",
    "axes[0, 1].set_title('Accuracy Comparison (R¬≤ Scores)')\n",
    "axes[0, 1].set_xticks(x)\n",
    "axes[0, 1].set_xticklabels(model_names, rotation=45)\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Chart 3: How well does my best model predict actual vs predicted values?\n",
    "best_model_obj = my_models[best_model]\n",
    "y_pred_best = best_model_obj.predict(X_test_scaled)\n",
    "\n",
    "axes[1, 0].scatter(y_test_eng, y_pred_best, alpha=0.6)\n",
    "axes[1, 0].plot([y_test_eng.min(), y_test_eng.max()], [y_test_eng.min(), y_test_eng.max()], 'r--', lw=2)\n",
    "axes[1, 0].set_xlabel('Actual House Values')\n",
    "axes[1, 0].set_ylabel('My Predicted Values')\n",
    "axes[1, 0].set_title(f'How Accurate Are My Predictions? - {best_model}')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Chart 4: Which features matter most? (if using Random Forest)\n",
    "if best_model == 'Random Forest':\n",
    "    feature_names_all = list(housing.feature_names) + new_features\n",
    "    importances = best_model_obj.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1][:10]  # Top 10 most important\n",
    "    \n",
    "    axes[1, 1].bar(range(len(indices)), importances[indices])\n",
    "    axes[1, 1].set_xlabel('Features')\n",
    "    axes[1, 1].set_ylabel('Importance')\n",
    "    axes[1, 1].set_title('What Features Matter Most for Predictions?')\n",
    "    axes[1, 1].set_xticks(range(len(indices)))\n",
    "    axes[1, 1].set_xticklabels([feature_names_all[i] for i in indices], rotation=45)\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "else:\n",
    "    axes[1, 1].text(0.5, 0.5, 'Feature importance\\nonly works with\\nRandom Forest!', \n",
    "                   ha='center', va='center', transform=axes[1, 1].transAxes)\n",
    "    axes[1, 1].set_title('Feature Importance Analysis')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"These charts help me understand which model works best and why!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7b4dac",
   "metadata": {},
   "source": [
    "## The Main Challenges I Need to Watch Out For\n",
    "\n",
    "From studying Chapter 1, I learned about the common pitfalls in ML that I need to be aware of:\n",
    "\n",
    "### 1. **Not Having Enough Data**\n",
    "- Most ML algorithms are data-hungry - they need thousands or even millions of examples\n",
    "- Sometimes getting more data is better than trying a fancier algorithm\n",
    "\n",
    "### 2. **My Training Data Doesn't Represent Reality**\n",
    "- If my training data isn't representative of what I'll encounter in real life, my model will fail\n",
    "- **Sampling bias**: This happens when my sample is too small or I collect data in a biased way\n",
    "\n",
    "### 3. **Messy, Poor-Quality Data**\n",
    "- Missing values, outliers, and noisy data can ruin my model\n",
    "- Wrong or inconsistent labels are also a big problem\n",
    "\n",
    "### 4. **Using Irrelevant Features**\n",
    "- **Feature selection**: I need to pick the most useful features for my problem\n",
    "- **Feature extraction**: Sometimes I can combine existing features to create better ones\n",
    "\n",
    "### 5. **Overfitting - When My Model Memorizes Instead of Learning**\n",
    "- My model works great on training data but fails on new data\n",
    "- Solutions: regularization, get more training data, use a simpler model\n",
    "\n",
    "### 6. **Underfitting - When My Model is Too Simple**\n",
    "- My model is too basic to capture the underlying patterns\n",
    "- Solutions: use a more complex model, add better features, reduce constraints\n",
    "\n",
    "Let me demonstrate what overfitting and underfitting look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06afa12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let me show what overfitting and underfitting actually look like!\n",
    "print(\"‚ö†Ô∏è MY OVERFITTING AND UNDERFITTING DEMONSTRATION\")\n",
    "\n",
    "# Creating a simple dataset to clearly show the concepts\n",
    "np.random.seed(42)\n",
    "X_demo = np.linspace(0, 1, 100).reshape(-1, 1)\n",
    "y_demo = 1.5 * X_demo.ravel() + 0.5 * np.sin(2 * np.pi * X_demo.ravel()) + 0.1 * np.random.randn(100)\n",
    "\n",
    "# Splitting my demo data\n",
    "X_train_demo, X_test_demo, y_train_demo, y_test_demo = train_test_split(\n",
    "    X_demo, y_demo, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# I'll create models with different levels of complexity to show the difference\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "my_complexity_models = {\n",
    "    'Too Simple (Underfitting)': Pipeline([\n",
    "        ('poly', PolynomialFeatures(degree=1)),\n",
    "        ('linear', LinearRegression())\n",
    "    ]),\n",
    "    'Just Right': Pipeline([\n",
    "        ('poly', PolynomialFeatures(degree=3)),\n",
    "        ('linear', LinearRegression())\n",
    "    ]),\n",
    "    'Too Complex (Overfitting)': Pipeline([\n",
    "        ('poly', PolynomialFeatures(degree=15)),\n",
    "        ('linear', LinearRegression())\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Let me visualize what each model does\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "for i, (name, model) in enumerate(my_complexity_models.items()):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    \n",
    "    # Training my model\n",
    "    model.fit(X_train_demo, y_train_demo)\n",
    "    \n",
    "    # Making predictions on a smooth line to see the pattern clearly\n",
    "    X_plot = np.linspace(0, 1, 300).reshape(-1, 1)\n",
    "    y_plot = model.predict(X_plot)\n",
    "    \n",
    "    # Checking how well it does on training vs test data\n",
    "    train_score = model.score(X_train_demo, y_train_demo)\n",
    "    test_score = model.score(X_test_demo, y_test_demo)\n",
    "    \n",
    "    # Creating my visualization\n",
    "    plt.scatter(X_train_demo, y_train_demo, alpha=0.6, label='Training data')\n",
    "    plt.scatter(X_test_demo, y_test_demo, alpha=0.6, label='Test data')\n",
    "    plt.plot(X_plot, y_plot, color='red', linewidth=2, label='My prediction')\n",
    "    plt.title(f'{name}\\nTraining R¬≤: {train_score:.3f}, Test R¬≤: {test_score:.3f}')\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('y')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìà What I learned from this:\")\n",
    "print(\"- Underfitting: My model is too simple - performs poorly on both training AND test data\")\n",
    "print(\"- Just Right: Good performance on both - this is what I want!\")\n",
    "print(\"- Overfitting: Great on training data but terrible on test data - memorized instead of learned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2261fd8",
   "metadata": {},
   "source": [
    "## Testing and Validation - Making Sure My Models Actually Work\n",
    "\n",
    "I learned that just because my model works on training data doesn't mean it's good. I need proper ways to test it!\n",
    "\n",
    "### Key Testing Concepts I Understand Now:\n",
    "- **Holdout validation**: Split my data into separate train/test sets (what I've been doing)\n",
    "- **Cross-validation**: Test my model multiple times with different splits for more confidence\n",
    "- **Validation set**: A third set for tuning my model settings (train/validation/test split)\n",
    "\n",
    "### The \"No Free Lunch\" Theorem\n",
    "This is interesting - there's no single best model that works for every problem. I have to actually test different models to see which one works best for MY specific data and problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddccf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let me try this cross-validation thing to get more reliable results\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "\n",
    "print(\"üéØ MY CROSS-VALIDATION EXPERIMENT\")\n",
    "\n",
    "# I'll test the same models but with cross-validation for more reliable results\n",
    "my_cv_models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Decision Tree': DecisionTreeRegressor(random_state=42),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=50, random_state=42)  # Fewer trees for speed\n",
    "}\n",
    "\n",
    "# Storing my cross-validation results\n",
    "cv_results = {}\n",
    "\n",
    "for name, model in my_cv_models.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    \n",
    "    # 5-fold cross-validation - this splits my data 5 different ways and tests each time\n",
    "    cv_scores = cross_val_score(model, X_train_scaled, y_train_eng, \n",
    "                               cv=5, scoring='neg_mean_squared_error')\n",
    "    cv_rmse = np.sqrt(-cv_scores)  # Converting to RMSE (positive values)\n",
    "    \n",
    "    cv_results[name] = cv_rmse\n",
    "    \n",
    "    print(f\"  All 5 test scores: {cv_rmse}\")\n",
    "    print(f\"  Average score: {cv_rmse.mean():.4f} (+/- {cv_rmse.std() * 2:.4f})\")\n",
    "\n",
    "# Visualizing my cross-validation results with a box plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "box_data = [cv_results[name] for name in my_cv_models.keys()]\n",
    "box_labels = list(my_cv_models.keys())\n",
    "\n",
    "plt.boxplot(box_data, labels=box_labels)\n",
    "plt.ylabel('RMSE (Lower = Better)')\n",
    "plt.title('Cross-Validation Results: Which Model is Most Consistent?')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüèÜ My most reliable model based on cross-validation:\")\n",
    "best_cv_model = min(cv_results.keys(), key=lambda x: cv_results[x].mean())\n",
    "print(f\"{best_cv_model} with average RMSE: {cv_results[best_cv_model].mean():.4f}\")\n",
    "print(\"Cross-validation gives me much more confidence in my results!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643935fa",
   "metadata": {},
   "source": [
    "## My Chapter 1 Summary - What I Learned\n",
    "\n",
    "### Key Concepts I Now Understand:\n",
    "\n",
    "1. **What Machine Learning Really Is**: Teaching computers to find patterns in data without programming every rule explicitly\n",
    "\n",
    "2. **Different Types of ML Systems**:\n",
    "   - Supervised (I have the answers) vs Unsupervised (I need to find hidden patterns)\n",
    "   - Batch (learn from all data at once) vs Online (learn continuously)\n",
    "   - Instance-based (compare to examples) vs Model-based (build a mathematical model)\n",
    "\n",
    "3. **The Main Challenges I Need to Watch For**:\n",
    "   - Not having enough good quality data\n",
    "   - Overfitting (memorizing instead of learning)\n",
    "   - Underfitting (being too simple to capture patterns)\n",
    "   - Using irrelevant features\n",
    "\n",
    "4. **How to Properly Test My Models**: Cross-validation gives me more confidence than just a single train/test split\n",
    "\n",
    "### Practical Skills I Developed:\n",
    "- ‚úÖ Loading and exploring real datasets\n",
    "- ‚úÖ Creating new features from existing ones\n",
    "- ‚úÖ Training multiple ML algorithms and comparing them\n",
    "- ‚úÖ Visualizing my results to understand what's happening\n",
    "- ‚úÖ Understanding why some models work better than others\n",
    "- ‚úÖ Using cross-validation for more reliable testing\n",
    "\n",
    "\n",
    "---*"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
