{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04673ddc",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfbedd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Image processing\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16, ResNet50, MobileNetV2\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input as vgg_preprocess\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input as resnet_preprocess\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as mobilenet_preprocess\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Utilities\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPU Available:\", len(tf.config.list_physical_devices('GPU')) > 0)\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca3ec7b",
   "metadata": {},
   "source": [
    "## 2. Dataset Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135ca414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "train_dir = 'train'\n",
    "val_dir = 'val'\n",
    "test_dir = 'test'\n",
    "\n",
    "# Get class names\n",
    "class_names = sorted(os.listdir(train_dir))\n",
    "num_classes = len(class_names)\n",
    "\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"\\nClass names: {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de101ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count images in each split\n",
    "def count_images(directory):\n",
    "    counts = {}\n",
    "    total = 0\n",
    "    for class_name in class_names:\n",
    "        class_path = os.path.join(directory, class_name)\n",
    "        if os.path.exists(class_path):\n",
    "            count = len([f for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
    "            counts[class_name] = count\n",
    "            total += count\n",
    "    return counts, total\n",
    "\n",
    "train_counts, train_total = count_images(train_dir)\n",
    "val_counts, val_total = count_images(val_dir)\n",
    "test_counts, test_total = count_images(test_dir)\n",
    "\n",
    "print(\"Dataset Statistics:\")\n",
    "print(f\"Training images: {train_total}\")\n",
    "print(f\"Validation images: {val_total}\")\n",
    "print(f\"Test images: {test_total}\")\n",
    "print(f\"Total images: {train_total + val_total + test_total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df18b29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class distribution\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Training distribution\n",
    "axes[0].bar(train_counts.keys(), train_counts.values(), color='steelblue')\n",
    "axes[0].set_title('Training Set Distribution', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Fish Species')\n",
    "axes[0].set_ylabel('Number of Images')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Validation distribution\n",
    "axes[1].bar(val_counts.keys(), val_counts.values(), color='salmon')\n",
    "axes[1].set_title('Validation Set Distribution', fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlabel('Fish Species')\n",
    "axes[1].set_ylabel('Number of Images')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Test distribution\n",
    "axes[2].bar(test_counts.keys(), test_counts.values(), color='lightgreen')\n",
    "axes[2].set_title('Test Set Distribution', fontsize=12, fontweight='bold')\n",
    "axes[2].set_xlabel('Fish Species')\n",
    "axes[2].set_ylabel('Number of Images')\n",
    "axes[2].tick_params(axis='x', rotation=45)\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detailed counts\n",
    "print(\"\\nDetailed class distribution:\")\n",
    "df_counts = pd.DataFrame({\n",
    "    'Class': class_names,\n",
    "    'Train': [train_counts.get(c, 0) for c in class_names],\n",
    "    'Val': [val_counts.get(c, 0) for c in class_names],\n",
    "    'Test': [test_counts.get(c, 0) for c in class_names]\n",
    "})\n",
    "df_counts['Total'] = df_counts['Train'] + df_counts['Val'] + df_counts['Test']\n",
    "print(df_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880b8212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images from each class\n",
    "def show_sample_images(directory, classes, samples_per_class=3):\n",
    "    fig, axes = plt.subplots(len(classes), samples_per_class, figsize=(15, len(classes)*3))\n",
    "    \n",
    "    for i, class_name in enumerate(classes):\n",
    "        class_path = os.path.join(directory, class_name)\n",
    "        images = [f for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        \n",
    "        for j in range(min(samples_per_class, len(images))):\n",
    "            img_path = os.path.join(class_path, images[j])\n",
    "            img = Image.open(img_path)\n",
    "            \n",
    "            if len(classes) == 1:\n",
    "                ax = axes[j]\n",
    "            else:\n",
    "                ax = axes[i, j]\n",
    "            \n",
    "            ax.imshow(img)\n",
    "            ax.axis('off')\n",
    "            if j == 0:\n",
    "                ax.set_title(f'{class_name}\\n{img.size[0]}x{img.size[1]}', \n",
    "                           fontsize=10, fontweight='bold')\n",
    "            else:\n",
    "                ax.set_title(f'{img.size[0]}x{img.size[1]}', fontsize=9)\n",
    "    \n",
    "    plt.suptitle('Sample Images from Each Class', fontsize=14, fontweight='bold', y=0.995)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_sample_images(train_dir, class_names, samples_per_class=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd2b8ef",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing and Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc67a5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image parameters\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "print(f\"Image size: {IMG_HEIGHT}x{IMG_WIDTH}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a2ad82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Only rescaling for validation and test\n",
    "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "val_generator = val_test_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = val_test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(f\"\\nClasses: {train_generator.class_indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65499b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize augmented images\n",
    "def show_augmented_images(generator, num_images=5):\n",
    "    images, labels = next(generator)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(15, 3))\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        axes[i].imshow(images[i])\n",
    "        class_idx = np.argmax(labels[i])\n",
    "        class_name = list(generator.class_indices.keys())[class_idx]\n",
    "        axes[i].set_title(f'{class_name}', fontsize=10, fontweight='bold')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle('Augmented Training Images', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_augmented_images(train_generator, num_images=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ac0bb2",
   "metadata": {},
   "source": [
    "## 4. Custom CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a5179e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build custom CNN model\n",
    "def build_custom_cnn(input_shape=(IMG_HEIGHT, IMG_WIDTH, 3), num_classes=num_classes):\n",
    "    model = models.Sequential([\n",
    "        # First Convolutional Block\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape, padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Second Convolutional Block\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Third Convolutional Block\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Fourth Convolutional Block\n",
    "        layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Flatten and Dense Layers\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy', keras.metrics.TopKCategoricalAccuracy(k=3, name='top_3_accuracy')]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create and display model\n",
    "custom_cnn = build_custom_cnn()\n",
    "custom_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1fcd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "checkpoint = callbacks.ModelCheckpoint(\n",
    "    'best_custom_cnn.keras',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Callbacks defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277ef341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train custom CNN\n",
    "print(\"Training Custom CNN...\")\n",
    "history_custom = custom_cnn.fit(\n",
    "    train_generator,\n",
    "    epochs=30,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[early_stopping, reduce_lr, checkpoint],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa940570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history for custom CNN\n",
    "def plot_training_history(history, model_name):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Accuracy\n",
    "    axes[0].plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    axes[0].plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "    if 'top_3_accuracy' in history.history:\n",
    "        axes[0].plot(history.history['top_3_accuracy'], label='Train Top-3 Acc', linestyle='--')\n",
    "        axes[0].plot(history.history['val_top_3_accuracy'], label='Val Top-3 Acc', linestyle='--')\n",
    "    axes[0].set_title(f'{model_name} - Accuracy', fontsize=12, fontweight='bold')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Accuracy')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Loss\n",
    "    axes[1].plot(history.history['loss'], label='Train Loss')\n",
    "    axes[1].plot(history.history['val_loss'], label='Val Loss')\n",
    "    axes[1].set_title(f'{model_name} - Loss', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Loss')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(history_custom, 'Custom CNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991501c8",
   "metadata": {},
   "source": [
    "## 5. Transfer Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0e4abe",
   "metadata": {},
   "source": [
    "### 5.1 VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a68cee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build VGG16 model\n",
    "def build_vgg16(input_shape=(IMG_HEIGHT, IMG_WIDTH, 3), num_classes=num_classes):\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    \n",
    "    # Freeze base model layers\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy', keras.metrics.TopKCategoricalAccuracy(k=3, name='top_3_accuracy')]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "vgg16_model = build_vgg16()\n",
    "print(\"VGG16 Model created!\")\n",
    "vgg16_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af20cb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train VGG16\n",
    "print(\"Training VGG16...\")\n",
    "history_vgg16 = vgg16_model.fit(\n",
    "    train_generator,\n",
    "    epochs=20,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "plot_training_history(history_vgg16, 'VGG16')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b09912",
   "metadata": {},
   "source": [
    "### 5.2 ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acd727f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build ResNet50 model\n",
    "def build_resnet50(input_shape=(IMG_HEIGHT, IMG_WIDTH, 3), num_classes=num_classes):\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    \n",
    "    # Freeze base model layers\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy', keras.metrics.TopKCategoricalAccuracy(k=3, name='top_3_accuracy')]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "resnet_model = build_resnet50()\n",
    "print(\"ResNet50 Model created!\")\n",
    "resnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195d8611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train ResNet50\n",
    "print(\"Training ResNet50...\")\n",
    "history_resnet = resnet_model.fit(\n",
    "    train_generator,\n",
    "    epochs=20,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "plot_training_history(history_resnet, 'ResNet50')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8163bf",
   "metadata": {},
   "source": [
    "### 5.3 MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d55233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build MobileNetV2 model\n",
    "def build_mobilenet(input_shape=(IMG_HEIGHT, IMG_WIDTH, 3), num_classes=num_classes):\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    \n",
    "    # Freeze base model layers\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy', keras.metrics.TopKCategoricalAccuracy(k=3, name='top_3_accuracy')]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "mobilenet_model = build_mobilenet()\n",
    "print(\"MobileNetV2 Model created!\")\n",
    "mobilenet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f5b984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train MobileNetV2\n",
    "print(\"Training MobileNetV2...\")\n",
    "history_mobilenet = mobilenet_model.fit(\n",
    "    train_generator,\n",
    "    epochs=20,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "plot_training_history(history_mobilenet, 'MobileNetV2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c720dad8",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f20f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate all models\n",
    "def evaluate_model(model, generator, model_name):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Evaluating {model_name}...\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Get predictions\n",
    "    generator.reset()\n",
    "    predictions = model.predict(generator, verbose=1)\n",
    "    y_pred = np.argmax(predictions, axis=1)\n",
    "    y_true = generator.classes\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    print(f\"\\n{model_name} Test Results:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # Classification report\n",
    "    print(f\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "    \n",
    "    return {\n",
    "        'model_name': model_name,\n",
    "        'accuracy': accuracy,\n",
    "        'predictions': predictions,\n",
    "        'y_pred': y_pred,\n",
    "        'y_true': y_true,\n",
    "        'confusion_matrix': cm\n",
    "    }\n",
    "\n",
    "# Evaluate all models\n",
    "results_custom = evaluate_model(custom_cnn, test_generator, 'Custom CNN')\n",
    "results_vgg16 = evaluate_model(vgg16_model, test_generator, 'VGG16')\n",
    "results_resnet = evaluate_model(resnet_model, test_generator, 'ResNet50')\n",
    "results_mobilenet = evaluate_model(mobilenet_model, test_generator, 'MobileNetV2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd76257d",
   "metadata": {},
   "source": [
    "## 7. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f84d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile results\n",
    "all_results = [results_custom, results_vgg16, results_resnet, results_mobilenet]\n",
    "\n",
    "# Create comparison dataframe\n",
    "comparison_df = pd.DataFrame([\n",
    "    {\n",
    "        'Model': result['model_name'],\n",
    "        'Test Accuracy': result['accuracy']\n",
    "    }\n",
    "    for result in all_results\n",
    "])\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL COMPARISON SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Find best model\n",
    "best_model_idx = comparison_df['Test Accuracy'].idxmax()\n",
    "best_model_name = comparison_df.loc[best_model_idx, 'Model']\n",
    "print(f\"\\nBest Model: {best_model_name}\")\n",
    "print(f\"Test Accuracy: {comparison_df.loc[best_model_idx, 'Test Accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebacaf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(comparison_df['Model'], comparison_df['Test Accuracy'], color='steelblue')\n",
    "plt.title('Model Accuracy Comparison', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels\n",
    "for i, v in enumerate(comparison_df['Test Accuracy']):\n",
    "    plt.text(i, v + 0.02, f'{v:.4f}', ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28da7dd7",
   "metadata": {},
   "source": [
    "## 8. Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5ab497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrices\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 14))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, result in enumerate(all_results):\n",
    "    cm = result['confusion_matrix']\n",
    "    \n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names,\n",
    "                ax=axes[idx], cbar=True)\n",
    "    axes[idx].set_title(f\"{result['model_name']} - Confusion Matrix\\n(Accuracy={result['accuracy']:.4f})\", \n",
    "                       fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_ylabel('True Label')\n",
    "    axes[idx].set_xlabel('Predicted Label')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4acf4b",
   "metadata": {},
   "source": [
    "## 9. Prediction Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc53f431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions\n",
    "def visualize_predictions(model, generator, class_names, num_images=12):\n",
    "    generator.reset()\n",
    "    images, labels = next(generator)\n",
    "    predictions = model.predict(images[:num_images])\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        axes[i].imshow(images[i])\n",
    "        \n",
    "        true_label = class_names[np.argmax(labels[i])]\n",
    "        pred_label = class_names[np.argmax(predictions[i])]\n",
    "        confidence = np.max(predictions[i])\n",
    "        \n",
    "        color = 'green' if true_label == pred_label else 'red'\n",
    "        axes[i].set_title(f'True: {true_label}\\nPred: {pred_label}\\nConf: {confidence:.2f}',\n",
    "                         color=color, fontweight='bold', fontsize=9)\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Get best model\n",
    "best_model_obj = [custom_cnn, vgg16_model, resnet_model, mobilenet_model][best_model_idx]\n",
    "\n",
    "print(f\"Predictions from Best Model ({best_model_name}):\")\n",
    "visualize_predictions(best_model_obj, test_generator, class_names, num_images=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec5c165",
   "metadata": {},
   "source": [
    "## 10. Visualization of CNN Learned Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61064148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature maps from custom CNN\n",
    "def visualize_feature_maps(model, image, layer_name, num_filters=16):\n",
    "    # Create a model that outputs the feature maps\n",
    "    layer_output = model.get_layer(layer_name).output\n",
    "    feature_model = models.Model(inputs=model.input, outputs=layer_output)\n",
    "    \n",
    "    # Get the feature maps\n",
    "    feature_maps = feature_model.predict(np.expand_dims(image, axis=0))\n",
    "    \n",
    "    # Plot the feature maps\n",
    "    cols = 8\n",
    "    rows = int(np.ceil(num_filters / cols))\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(16, rows*2))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i in range(min(num_filters, feature_maps.shape[-1])):\n",
    "        axes[i].imshow(feature_maps[0, :, :, i], cmap='viridis')\n",
    "        axes[i].axis('off')\n",
    "        axes[i].set_title(f'Filter {i+1}', fontsize=8)\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for i in range(num_filters, len(axes)):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle(f'Feature Maps from Layer: {layer_name}', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Get a sample image\n",
    "test_generator.reset()\n",
    "sample_images, sample_labels = next(test_generator)\n",
    "sample_image = sample_images[0]\n",
    "\n",
    "# Show original image\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(sample_image)\n",
    "plt.title('Original Image', fontweight='bold')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Visualize feature maps from different layers\n",
    "try:\n",
    "    visualize_feature_maps(custom_cnn, sample_image, 'conv2d', num_filters=32)\n",
    "    visualize_feature_maps(custom_cnn, sample_image, 'conv2d_2', num_filters=32)\n",
    "    visualize_feature_maps(custom_cnn, sample_image, 'conv2d_4', num_filters=32)\n",
    "except Exception as e:\n",
    "    print(f\"Note: Feature map visualization requires specific layer names. Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49eba5d",
   "metadata": {},
   "source": [
    "## 11. Summary and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f9ead9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FISH IMAGE CLASSIFICATION PROJECT SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n1. Dataset Statistics:\")\n",
    "print(f\"   - Number of classes: {num_classes}\")\n",
    "print(f\"   - Training images: {train_total}\")\n",
    "print(f\"   - Validation images: {val_total}\")\n",
    "print(f\"   - Test images: {test_total}\")\n",
    "print(f\"   - Image size: {IMG_HEIGHT}x{IMG_WIDTH}\")\n",
    "\n",
    "print(f\"\\n2. Models Trained:\")\n",
    "for i, result in enumerate(all_results, 1):\n",
    "    print(f\"   {i}. {result['model_name']}\")\n",
    "\n",
    "print(f\"\\n3. Best Model: {best_model_name}\")\n",
    "print(f\"   - Test Accuracy: {comparison_df.loc[best_model_idx, 'Test Accuracy']:.4f}\")\n",
    "\n",
    "print(f\"\\n4. Key Techniques Used:\")\n",
    "print(f\"   - Data augmentation (rotation, shift, zoom, flip)\")\n",
    "print(f\"   - Custom CNN architecture with batch normalization\")\n",
    "print(f\"   - Transfer learning (VGG16, ResNet50, MobileNetV2)\")\n",
    "print(f\"   - Callbacks (EarlyStopping, ReduceLROnPlateau, ModelCheckpoint)\")\n",
    "print(f\"   - Comprehensive evaluation and visualization\")\n",
    "\n",
    "print(f\"\\n5. Performance Ranking:\")\n",
    "ranked_df = comparison_df.sort_values('Test Accuracy', ascending=False).reset_index(drop=True)\n",
    "for i, row in ranked_df.iterrows():\n",
    "    print(f\"   {i+1}. {row['Model']:20s} - Accuracy: {row['Test Accuracy']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PROJECT COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
