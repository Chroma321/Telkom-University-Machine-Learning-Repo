{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bdb3f4f",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11087805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essential Data Science Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# Machine Learning Libraries\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif, RFE\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Classification Models\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Class Imbalance Handling\n",
    "try:\n",
    "    from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "    from imblearn.under_sampling import RandomUnderSampler\n",
    "    from imblearn.combine import SMOTETomek\n",
    "    IMBALANCE_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è imbalanced-learn not available. Will use basic resampling techniques.\")\n",
    "    IMBALANCE_AVAILABLE = False\n",
    "\n",
    "# Evaluation Metrics\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, roc_auc_score, roc_curve,\n",
    "    precision_recall_curve, average_precision_score, f1_score,\n",
    "    precision_score, recall_score, accuracy_score\n",
    ")\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n",
    "print(f\"üìä NumPy version: {np.__version__}\")\n",
    "print(f\"üìä Pandas version: {pd.__version__}\")\n",
    "print(f\"ü§ñ Imbalanced-learn available: {IMBALANCE_AVAILABLE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8191cd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading Function\n",
    "def load_fraud_data():\n",
    "    \"\"\"\n",
    "    Load fraud detection datasets with error handling\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Try to load the actual datasets\n",
    "        print(\"üîç Looking for fraud detection datasets...\")\n",
    "        \n",
    "        train_df = pd.read_csv('train_transaction.csv')\n",
    "        test_df = pd.read_csv('test_transaction.csv')\n",
    "        \n",
    "        print(f\"‚úÖ Successfully loaded training data: {train_df.shape}\")\n",
    "        print(f\"‚úÖ Successfully loaded test data: {test_df.shape}\")\n",
    "        \n",
    "        return train_df, test_df\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(\"‚ö†Ô∏è Dataset files not found. Creating sample fraud detection dataset for demonstration...\")\n",
    "        \n",
    "        # Create realistic sample fraud detection data\n",
    "        np.random.seed(42)\n",
    "        n_samples = 10000\n",
    "        \n",
    "        # Generate sample transaction data\n",
    "        data = {\n",
    "            'TransactionID': range(1, n_samples + 1),\n",
    "            'TransactionAmt': np.random.lognormal(3, 1, n_samples),\n",
    "            'ProductCD': np.random.choice(['W', 'C', 'R', 'H', 'S'], n_samples),\n",
    "            'card1': np.random.randint(1000, 20000, n_samples),\n",
    "            'card2': np.random.choice([100, 200, 300, 400, 500, None], n_samples),\n",
    "            'card3': np.random.choice([100, 150, 185, None], n_samples),\n",
    "            'card4': np.random.choice(['mastercard', 'visa', 'american express', 'discover'], n_samples),\n",
    "            'card5': np.random.choice([100, 101, 102, 200, 201, None], n_samples),\n",
    "            'card6': np.random.choice(['credit', 'debit'], n_samples),\n",
    "            'addr1': np.random.randint(100, 600, n_samples),\n",
    "            'addr2': np.random.randint(10, 100, n_samples),\n",
    "            'dist1': np.random.exponential(50, n_samples),\n",
    "            'dist2': np.random.exponential(50, n_samples),\n",
    "            'P_emaildomain': np.random.choice(['gmail.com', 'yahoo.com', 'hotmail.com', None], n_samples),\n",
    "            'R_emaildomain': np.random.choice(['gmail.com', 'yahoo.com', 'hotmail.com', None], n_samples),\n",
    "            'C1': np.random.randint(0, 20, n_samples),\n",
    "            'C2': np.random.randint(0, 20, n_samples),\n",
    "            'C3': np.random.randint(0, 20, n_samples),\n",
    "            'C4': np.random.randint(0, 50, n_samples),\n",
    "            'C5': np.random.randint(0, 10, n_samples),\n",
    "            'D1': np.random.exponential(10, n_samples),\n",
    "            'D2': np.random.exponential(10, n_samples),\n",
    "            'D3': np.random.exponential(10, n_samples),\n",
    "            'V1': np.random.normal(0, 1, n_samples),\n",
    "            'V2': np.random.normal(0, 1, n_samples),\n",
    "            'V3': np.random.normal(0, 1, n_samples),\n",
    "            'V4': np.random.normal(0, 1, n_samples),\n",
    "            'V5': np.random.normal(0, 1, n_samples),\n",
    "        }\n",
    "        \n",
    "        # Create fraud labels (imbalanced - about 3.5% fraud)\n",
    "        fraud_probability = (\n",
    "            0.01 +\n",
    "            (data['TransactionAmt'] > 1000) * 0.05 +\n",
    "            (pd.Series(data['card2']).isna()) * 0.02 +\n",
    "            (pd.Series(data['P_emaildomain']).isna()) * 0.03 +\n",
    "            np.random.normal(0, 0.01, n_samples)\n",
    "        )\n",
    "        \n",
    "        fraud_probability = np.clip(fraud_probability, 0, 1)\n",
    "        is_fraud = np.random.binomial(1, fraud_probability, n_samples)\n",
    "        data['isFraud'] = is_fraud\n",
    "        \n",
    "        # Create DataFrames\n",
    "        train_df = pd.DataFrame(data)\n",
    "        \n",
    "        # Create test set (without isFraud column)\n",
    "        test_data = data.copy()\n",
    "        del test_data['isFraud']\n",
    "        test_data['TransactionID'] = range(n_samples + 1, 2 * n_samples + 1)\n",
    "        test_df = pd.DataFrame(test_data)\n",
    "        \n",
    "        print(f\"üìä Sample training data created: {train_df.shape}\")\n",
    "        print(f\"üìä Sample test data created: {test_df.shape}\")\n",
    "        print(f\"üéØ Fraud rate: {train_df['isFraud'].mean():.3f} ({train_df['isFraud'].sum()} fraudulent transactions)\")\n",
    "        \n",
    "        return train_df, test_df\n",
    "\n",
    "# Load the data\n",
    "train_data, test_data = load_fraud_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b65b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Data Inspection\n",
    "print(\"=\" * 60)\n",
    "print(\"           DATASET OVERVIEW\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nüìä Training Data Shape: {train_data.shape}\")\n",
    "print(f\"üìä Test Data Shape: {test_data.shape}\")\n",
    "print(f\"üéØ Target Variable: isFraud\")\n",
    "print(f\"üîç Number of Features: {train_data.shape[1] - 1}\")\n",
    "\n",
    "# Check target variable\n",
    "if 'isFraud' in train_data.columns:\n",
    "    fraud_count = train_data['isFraud'].sum()\n",
    "    total_count = len(train_data)\n",
    "    fraud_rate = fraud_count / total_count\n",
    "    \n",
    "    print(f\"\\nüéØ TARGET VARIABLE ANALYSIS:\")\n",
    "    print(f\"   ‚Ä¢ Total Transactions: {total_count:,}\")\n",
    "    print(f\"   ‚Ä¢ Fraudulent Transactions: {fraud_count:,}\")\n",
    "    print(f\"   ‚Ä¢ Legitimate Transactions: {total_count - fraud_count:,}\")\n",
    "    print(f\"   ‚Ä¢ Fraud Rate: {fraud_rate:.3%}\")\n",
    "    \n",
    "    if fraud_rate < 0.1:\n",
    "        print(f\"   ‚ö†Ô∏è HIGHLY IMBALANCED DATASET - Will need special handling!\")\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nüìã TRAINING DATA PREVIEW:\")\n",
    "display(train_data.head())\n",
    "\n",
    "# Data types and missing values\n",
    "print(\"\\nüï≥Ô∏è MISSING VALUES ANALYSIS:\")\n",
    "missing_train = train_data.isnull().sum()\n",
    "missing_train_pct = (missing_train / len(train_data)) * 100\n",
    "\n",
    "missing_summary = pd.DataFrame({\n",
    "    'Missing_Count': missing_train,\n",
    "    'Missing_Percentage': missing_train_pct\n",
    "})\n",
    "\n",
    "missing_summary = missing_summary[missing_summary['Missing_Count'] > 0]\n",
    "missing_summary = missing_summary.sort_values('Missing_Percentage', ascending=False)\n",
    "\n",
    "if len(missing_summary) > 0:\n",
    "    print(\"üö® Columns with missing values:\")\n",
    "    display(missing_summary.round(2))\n",
    "else:\n",
    "    print(\"‚úÖ No missing values found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15f18fc",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1338e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable distribution visualization\n",
    "print(\"üéØ TARGET VARIABLE ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Calculate fraud statistics\n",
    "fraud_counts = train_data['isFraud'].value_counts()\n",
    "fraud_percentages = train_data['isFraud'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(f\"üìä Class Distribution:\")\n",
    "print(f\"   ‚Ä¢ Legitimate (0): {fraud_counts[0]:,} transactions ({fraud_percentages[0]:.2f}%)\")\n",
    "print(f\"   ‚Ä¢ Fraudulent (1): {fraud_counts[1]:,} transactions ({fraud_percentages[1]:.2f}%)\")\n",
    "print(f\"   ‚Ä¢ Imbalance Ratio: 1:{fraud_counts[0]/fraud_counts[1]:.1f}\")\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Bar plot\n",
    "fraud_counts.plot(kind='bar', ax=axes[0], color=['skyblue', 'salmon'])\n",
    "axes[0].set_title('Fraud Distribution (Count)')\n",
    "axes[0].set_xlabel('Is Fraud')\n",
    "axes[0].set_ylabel('Number of Transactions')\n",
    "axes[0].set_xticklabels(['Legitimate', 'Fraudulent'], rotation=0)\n",
    "\n",
    "# Pie chart\n",
    "axes[1].pie(fraud_counts.values, labels=['Legitimate', 'Fraudulent'], \n",
    "           autopct='%1.2f%%', colors=['skyblue', 'salmon'])\n",
    "axes[1].set_title('Fraud Distribution (Percentage)')\n",
    "\n",
    "# Log scale bar plot\n",
    "fraud_counts.plot(kind='bar', ax=axes[2], color=['skyblue', 'salmon'], logy=True)\n",
    "axes[2].set_title('Fraud Distribution (Log Scale)')\n",
    "axes[2].set_xlabel('Is Fraud')\n",
    "axes[2].set_ylabel('Number of Transactions (Log Scale)')\n",
    "axes[2].set_xticklabels(['Legitimate', 'Fraudulent'], rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede0a742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transaction amount analysis\n",
    "print(\"üí≥ TRANSACTION AMOUNT ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if 'TransactionAmt' in train_data.columns:\n",
    "    fraud_amounts = train_data[train_data['isFraud'] == 1]['TransactionAmt']\n",
    "    legit_amounts = train_data[train_data['isFraud'] == 0]['TransactionAmt']\n",
    "    \n",
    "    print(f\"üìà Amount Statistics:\")\n",
    "    print(f\"\\nFraudulent Transactions:\")\n",
    "    print(f\"   ‚Ä¢ Mean: ${fraud_amounts.mean():.2f}\")\n",
    "    print(f\"   ‚Ä¢ Median: ${fraud_amounts.median():.2f}\")\n",
    "    print(f\"   ‚Ä¢ Max: ${fraud_amounts.max():.2f}\")\n",
    "    \n",
    "    print(f\"\\nLegitimate Transactions:\")\n",
    "    print(f\"   ‚Ä¢ Mean: ${legit_amounts.mean():.2f}\")\n",
    "    print(f\"   ‚Ä¢ Median: ${legit_amounts.median():.2f}\")\n",
    "    print(f\"   ‚Ä¢ Max: ${legit_amounts.max():.2f}\")\n",
    "    \n",
    "    # Visualization\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Box plot comparison\n",
    "    train_data.boxplot(column='TransactionAmt', by='isFraud', ax=axes[0])\n",
    "    axes[0].set_title('Transaction Amount by Fraud Status')\n",
    "    axes[0].set_xlabel('Is Fraud')\n",
    "    axes[0].set_ylabel('Transaction Amount ($)')\n",
    "    \n",
    "    # Histogram comparison\n",
    "    axes[1].hist(legit_amounts, bins=50, alpha=0.7, label='Legitimate', density=True)\n",
    "    axes[1].hist(fraud_amounts, bins=50, alpha=0.7, label='Fraudulent', density=True)\n",
    "    axes[1].set_title('Transaction Amount Distribution')\n",
    "    axes[1].set_xlabel('Transaction Amount ($)')\n",
    "    axes[1].set_ylabel('Density')\n",
    "    axes[1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17b60f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature correlation analysis\n",
    "print(\"üîó FEATURE CORRELATION ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Get numerical columns for correlation analysis\n",
    "numerical_cols = train_data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "if 'TransactionID' in numerical_cols:\n",
    "    numerical_cols.remove('TransactionID')\n",
    "\n",
    "print(f\"üìä Analyzing correlations for {len(numerical_cols)} numerical features\")\n",
    "\n",
    "if len(numerical_cols) > 1:\n",
    "    # Calculate correlations with target\n",
    "    correlations_with_target = train_data[numerical_cols].corrwith(train_data['isFraud']).sort_values(ascending=False)\n",
    "    correlations_with_target = correlations_with_target.drop('isFraud', errors='ignore')\n",
    "    \n",
    "    print(f\"\\nüéØ Top correlations with fraud target:\")\n",
    "    print(\"\\nTop 10 features by absolute correlation:\")\n",
    "    top_corr = correlations_with_target.abs().sort_values(ascending=False).head(10)\n",
    "    for feature, corr in top_corr.items():\n",
    "        actual_corr = correlations_with_target[feature]\n",
    "        print(f\"   ‚Ä¢ {feature}: {actual_corr:.4f}\")\n",
    "    \n",
    "    # Visualization\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    correlations_with_target.plot(kind='barh', color=['red' if x < 0 else 'blue' for x in correlations_with_target])\n",
    "    plt.title('Feature Correlations with Fraud Target')\n",
    "    plt.xlabel('Correlation Coefficient')\n",
    "    plt.axvline(x=0, color='black', linestyle='--', alpha=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Categorical features analysis\n",
    "categorical_cols = train_data.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"\\nüìä CATEGORICAL FEATURES ANALYSIS\")\n",
    "print(f\"Categorical columns found: {len(categorical_cols)}\")\n",
    "\n",
    "if len(categorical_cols) > 0:\n",
    "    for col in categorical_cols[:3]:  # Analyze first 3 categorical columns\n",
    "        if col in train_data.columns:\n",
    "            print(f\"\\nüìä Analysis for {col}:\")\n",
    "            cat_analysis = train_data.groupby(col, dropna=False)['isFraud'].agg(['count', 'sum', 'mean'])\n",
    "            cat_analysis.columns = ['Total', 'Fraud_Count', 'Fraud_Rate']\n",
    "            cat_analysis = cat_analysis.sort_values('Fraud_Rate', ascending=False)\n",
    "            display(cat_analysis.head().round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f330778",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad25f9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "print(\"üõ†Ô∏è DATA PREPROCESSING\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create a copy for preprocessing\n",
    "df_processed = train_data.copy()\n",
    "\n",
    "# Separate features and target\n",
    "if 'TransactionID' in df_processed.columns:\n",
    "    df_processed = df_processed.drop('TransactionID', axis=1)\n",
    "\n",
    "X = df_processed.drop('isFraud', axis=1)\n",
    "y = df_processed['isFraud']\n",
    "\n",
    "print(f\"üìä Features shape: {X.shape}\")\n",
    "print(f\"üéØ Target shape: {y.shape}\")\n",
    "\n",
    "# Handle missing values\n",
    "print(f\"\\nüîß Handling missing values...\")\n",
    "missing_counts = X.isnull().sum()\n",
    "columns_with_missing = missing_counts[missing_counts > 0].index.tolist()\n",
    "\n",
    "if len(columns_with_missing) > 0:\n",
    "    print(f\"Found missing values in {len(columns_with_missing)} columns\")\n",
    "    \n",
    "    for col in columns_with_missing:\n",
    "        if X[col].dtype == 'object':\n",
    "            # Fill categorical missing values with 'Missing'\n",
    "            X[col] = X[col].fillna('Missing')\n",
    "            print(f\"   ‚Ä¢ {col}: Filled categorical missing values with 'Missing'\")\n",
    "        else:\n",
    "            # Fill numerical missing values with median\n",
    "            X[col] = X[col].fillna(X[col].median())\n",
    "            print(f\"   ‚Ä¢ {col}: Filled numerical missing values with median\")\n",
    "else:\n",
    "    print(\"‚úÖ No missing values found\")\n",
    "\n",
    "# Feature engineering\n",
    "print(f\"\\nüîß Feature engineering...\")\n",
    "\n",
    "# Create new features if TransactionAmt exists\n",
    "if 'TransactionAmt' in X.columns:\n",
    "    # Amount-based features\n",
    "    X['TransactionAmt_log'] = np.log1p(X['TransactionAmt'])\n",
    "    X['TransactionAmt_sqrt'] = np.sqrt(X['TransactionAmt'])\n",
    "    X['IsHighAmount'] = (X['TransactionAmt'] > X['TransactionAmt'].quantile(0.95)).astype(int)\n",
    "    print(\"   ‚Ä¢ Created amount-based features\")\n",
    "\n",
    "# Count missing values across features for each transaction\n",
    "original_missing = train_data.drop(['isFraud', 'TransactionID'], axis=1, errors='ignore').isnull().sum(axis=1)\n",
    "X['MissingValues_Count'] = original_missing\n",
    "print(\"   ‚Ä¢ Created missing values count feature\")\n",
    "\n",
    "# Encode categorical variables\n",
    "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"\\nüè∑Ô∏è Encoding {len(categorical_features)} categorical features...\")\n",
    "\n",
    "label_encoders = {}\n",
    "for col in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "    print(f\"   ‚Ä¢ Encoded {col}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Preprocessing completed\")\n",
    "print(f\"üìä Final feature set shape: {X.shape}\")\n",
    "print(f\"üîç Feature names: {list(X.columns[:10])}{'...' if len(X.columns) > 10 else ''}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92948b9d",
   "metadata": {},
   "source": [
    "## 4. Train-Test Split and Class Imbalance Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8defdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "print(\"‚úÇÔ∏è TRAIN-TEST SPLIT\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"üìä Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"üìä Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"üéØ Training fraud rate: {y_train.mean():.3%}\")\n",
    "print(f\"üéØ Test fraud rate: {y_test.mean():.3%}\")\n",
    "\n",
    "# Handle class imbalance\n",
    "print(f\"\\n‚öñÔ∏è HANDLING CLASS IMBALANCE\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Original distribution\n",
    "original_fraud_count = y_train.sum()\n",
    "original_legit_count = len(y_train) - original_fraud_count\n",
    "print(f\"Original distribution - Legitimate: {original_legit_count}, Fraudulent: {original_fraud_count}\")\n",
    "\n",
    "# Apply SMOTE if available, otherwise use simple oversampling\n",
    "if IMBALANCE_AVAILABLE:\n",
    "    print(\"üîÑ Applying SMOTE oversampling...\")\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "else:\n",
    "    print(\"üîÑ Applying random oversampling...\")\n",
    "    # Simple random oversampling\n",
    "    fraud_indices = y_train[y_train == 1].index\n",
    "    legit_indices = y_train[y_train == 0].index\n",
    "    \n",
    "    # Oversample fraud cases to balance\n",
    "    n_fraud_needed = len(legit_indices) - len(fraud_indices)\n",
    "    fraud_oversample_indices = np.random.choice(fraud_indices, size=n_fraud_needed, replace=True)\n",
    "    \n",
    "    # Combine original and oversampled indices\n",
    "    balanced_indices = np.concatenate([legit_indices, fraud_indices, fraud_oversample_indices])\n",
    "    \n",
    "    X_train_balanced = X_train.loc[balanced_indices]\n",
    "    y_train_balanced = y_train.loc[balanced_indices]\n",
    "\n",
    "# Check new distribution\n",
    "new_fraud_count = y_train_balanced.sum()\n",
    "new_legit_count = len(y_train_balanced) - new_fraud_count\n",
    "print(f\"Balanced distribution - Legitimate: {new_legit_count}, Fraudulent: {new_fraud_count}\")\n",
    "print(f\"New fraud rate: {y_train_balanced.mean():.3%}\")\n",
    "print(f\"‚úÖ Class imbalance handled successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397a62e2",
   "metadata": {},
   "source": [
    "## 5. Model Implementation and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9399b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define evaluation functions\n",
    "def evaluate_fraud_model(y_true, y_pred, y_pred_proba, model_name):\n",
    "    \"\"\"\n",
    "    Comprehensive evaluation for fraud detection models\n",
    "    \"\"\"\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    auc_roc = roc_auc_score(y_true, y_pred_proba)\n",
    "    auc_pr = average_precision_score(y_true, y_pred_proba)\n",
    "    \n",
    "    print(f\"\\nüìä {model_name} Performance:\")\n",
    "    print(f\"   ‚Ä¢ Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"   ‚Ä¢ Precision: {precision:.4f}\")\n",
    "    print(f\"   ‚Ä¢ Recall: {recall:.4f}\")\n",
    "    print(f\"   ‚Ä¢ F1-Score: {f1:.4f}\")\n",
    "    print(f\"   ‚Ä¢ ROC AUC: {auc_roc:.4f}\")\n",
    "    print(f\"   ‚Ä¢ PR AUC: {auc_pr:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'Accuracy': accuracy, 'Precision': precision, 'Recall': recall,\n",
    "        'F1': f1, 'ROC_AUC': auc_roc, 'PR_AUC': auc_pr\n",
    "    }\n",
    "\n",
    "# Initialize fraud detection models\n",
    "fraud_models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42, n_estimators=100),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'Neural Network': MLPClassifier(random_state=42, max_iter=300)\n",
    "}\n",
    "\n",
    "print(f\"ü§ñ TRAINING FRAUD DETECTION MODELS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Initialized {len(fraud_models)} models for fraud detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f15504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models with scaling pipeline\n",
    "results = {}\n",
    "trained_models = {}\n",
    "scalers = {}\n",
    "\n",
    "for name, model in fraud_models.items():\n",
    "    print(f\"\\nüîÑ Training {name}...\")\n",
    "    \n",
    "    # Create pipeline with scaling\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    \n",
    "    # Train the model\n",
    "    pipeline.fit(X_train_balanced, y_train_balanced)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    y_pred_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Evaluate\n",
    "    metrics = evaluate_fraud_model(y_test, y_pred, y_pred_proba, name)\n",
    "    results[name] = metrics\n",
    "    trained_models[name] = pipeline\n",
    "\n",
    "print(\"\\n‚úÖ All models trained successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca57434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model comparison\n",
    "print(\"üìä MODEL COMPARISON\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df = results_df.sort_values('F1', ascending=False)\n",
    "\n",
    "print(\"\\nüèÜ Model Rankings (by F1-Score):\")\n",
    "display(results_df.round(4))\n",
    "\n",
    "# Visualize results\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1', 'ROC_AUC', 'PR_AUC']\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    ax = axes[i//3, i%3]\n",
    "    results_df[metric].plot(kind='bar', ax=ax, color='skyblue')\n",
    "    ax.set_title(f'{metric} Comparison')\n",
    "    ax.set_xlabel('Models')\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Best model\n",
    "best_model_name = results_df.index[0]\n",
    "best_f1 = results_df.loc[best_model_name, 'F1']\n",
    "print(f\"\\nü•á Best performing model: {best_model_name} (F1-Score: {best_f1:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed49e8d5",
   "metadata": {},
   "source": [
    "## 6. Detailed Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c6b3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed analysis of best model\n",
    "print(f\"üîç DETAILED ANALYSIS: {best_model_name}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "best_model = trained_models[best_model_name]\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "y_pred_proba_best = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred_best)\n",
    "print(\"\\nüìä Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nüìã Detailed Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_best, target_names=['Legitimate', 'Fraudulent']))\n",
    "\n",
    "# Visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Confusion Matrix Heatmap\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0,0],\n",
    "           xticklabels=['Legitimate', 'Fraudulent'],\n",
    "           yticklabels=['Legitimate', 'Fraudulent'])\n",
    "axes[0,0].set_title('Confusion Matrix')\n",
    "axes[0,0].set_ylabel('True Label')\n",
    "axes[0,0].set_xlabel('Predicted Label')\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba_best)\n",
    "axes[0,1].plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {results_df.loc[best_model_name, \"ROC_AUC\"]:.4f})')\n",
    "axes[0,1].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "axes[0,1].set_xlabel('False Positive Rate')\n",
    "axes[0,1].set_ylabel('True Positive Rate')\n",
    "axes[0,1].set_title('ROC Curve')\n",
    "axes[0,1].legend()\n",
    "\n",
    "# Precision-Recall Curve\n",
    "precision_vals, recall_vals, _ = precision_recall_curve(y_test, y_pred_proba_best)\n",
    "axes[1,0].plot(recall_vals, precision_vals, color='blue', lw=2,\n",
    "              label=f'PR curve (AUC = {results_df.loc[best_model_name, \"PR_AUC\"]:.4f})')\n",
    "axes[1,0].set_xlabel('Recall')\n",
    "axes[1,0].set_ylabel('Precision')\n",
    "axes[1,0].set_title('Precision-Recall Curve')\n",
    "axes[1,0].legend()\n",
    "\n",
    "# Prediction Probability Distribution\n",
    "fraud_proba = y_pred_proba_best[y_test == 1]\n",
    "legit_proba = y_pred_proba_best[y_test == 0]\n",
    "\n",
    "axes[1,1].hist(legit_proba, bins=30, alpha=0.7, label='Legitimate', density=True)\n",
    "axes[1,1].hist(fraud_proba, bins=30, alpha=0.7, label='Fraudulent', density=True)\n",
    "axes[1,1].set_xlabel('Predicted Fraud Probability')\n",
    "axes[1,1].set_ylabel('Density')\n",
    "axes[1,1].set_title('Prediction Probability Distribution')\n",
    "axes[1,1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Business Impact Analysis\n",
    "print(f\"\\nüí∞ BUSINESS IMPACT ANALYSIS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(f\"True Positives (Correctly detected fraud): {tp}\")\n",
    "print(f\"False Positives (False alarms): {fp}\")\n",
    "print(f\"False Negatives (Missed fraud): {fn}\")\n",
    "print(f\"True Negatives (Correctly identified legitimate): {tn}\")\n",
    "\n",
    "if 'TransactionAmt' in X.columns:\n",
    "    # Estimate financial impact (simplified)\n",
    "    avg_fraud_amount = train_data[train_data['isFraud'] == 1]['TransactionAmt'].mean()\n",
    "    detected_fraud_value = tp * avg_fraud_amount\n",
    "    missed_fraud_value = fn * avg_fraud_amount\n",
    "    \n",
    "    print(f\"\\nüíµ Estimated Financial Impact:\")\n",
    "    print(f\"   ‚Ä¢ Fraud detected and prevented: ${detected_fraud_value:,.2f}\")\n",
    "    print(f\"   ‚Ä¢ Fraud missed (potential loss): ${missed_fraud_value:,.2f}\")\n",
    "    print(f\"   ‚Ä¢ Detection rate: {tp/(tp+fn):.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac13b858",
   "metadata": {},
   "source": [
    "## 7. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21cca66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance analysis\n",
    "print(f\"üîç FEATURE IMPORTANCE ANALYSIS: {best_model_name}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    model_step = best_model.named_steps['model']\n",
    "    feature_names = X.columns\n",
    "    \n",
    "    if hasattr(model_step, 'feature_importances_'):\n",
    "        # Tree-based models\n",
    "        importance = model_step.feature_importances_\n",
    "        \n",
    "        importance_df = pd.DataFrame({\n",
    "            'feature': feature_names,\n",
    "            'importance': importance\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "        print(f\"\\nüèÜ Top 15 Most Important Features:\")\n",
    "        display(importance_df.head(15).round(4))\n",
    "        \n",
    "        # Visualization\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        top_features = importance_df.head(15)\n",
    "        plt.barh(range(len(top_features)), top_features['importance'])\n",
    "        plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "        plt.xlabel('Feature Importance')\n",
    "        plt.title(f'Top 15 Feature Importance - {best_model_name}')\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    elif hasattr(model_step, 'coef_'):\n",
    "        # Linear models\n",
    "        coefficients = model_step.coef_[0]\n",
    "        \n",
    "        coef_df = pd.DataFrame({\n",
    "            'feature': feature_names,\n",
    "            'coefficient': coefficients,\n",
    "            'abs_coefficient': np.abs(coefficients)\n",
    "        }).sort_values('abs_coefficient', ascending=False)\n",
    "        \n",
    "        print(f\"\\nüèÜ Top 15 Most Influential Features:\")\n",
    "        display(coef_df.head(15).round(4))\n",
    "        \n",
    "        # Visualization\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        top_features = coef_df.head(15)\n",
    "        colors = ['red' if x < 0 else 'blue' for x in top_features['coefficient']]\n",
    "        plt.barh(range(len(top_features)), top_features['coefficient'], color=colors)\n",
    "        plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "        plt.xlabel('Coefficient Value')\n",
    "        plt.title(f'Top 15 Feature Coefficients - {best_model_name}')\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    else:\n",
    "        print(f\"Feature importance not available for {best_model_name}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Could not extract feature importance: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7c56e7",
   "metadata": {},
   "source": [
    "## 8. Final Results and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2987b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final comprehensive results\n",
    "print(\"=\" * 70)\n",
    "print(\"           FRAUD DETECTION PIPELINE - FINAL RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nüìä DATASET SUMMARY:\")\n",
    "print(f\"   ‚Ä¢ Total transactions analyzed: {len(train_data):,}\")\n",
    "print(f\"   ‚Ä¢ Fraudulent transactions: {train_data['isFraud'].sum():,} ({train_data['isFraud'].mean():.2%})\")\n",
    "print(f\"   ‚Ä¢ Features used: {X.shape[1]}\")\n",
    "print(f\"   ‚Ä¢ Test set size: {len(X_test):,} transactions\")\n",
    "\n",
    "print(f\"\\nüèÜ BEST MODEL: {best_model_name}\")\n",
    "best_metrics = results_df.loc[best_model_name]\n",
    "print(f\"   ‚Ä¢ F1-Score: {best_metrics['F1']:.4f}\")\n",
    "print(f\"   ‚Ä¢ Precision: {best_metrics['Precision']:.4f} (% of fraud predictions that are correct)\")\n",
    "print(f\"   ‚Ä¢ Recall: {best_metrics['Recall']:.4f} (% of actual fraud detected)\")\n",
    "print(f\"   ‚Ä¢ ROC AUC: {best_metrics['ROC_AUC']:.4f}\")\n",
    "print(f\"   ‚Ä¢ PR AUC: {best_metrics['PR_AUC']:.4f}\")\n",
    "\n",
    "print(f\"\\nüéØ MODEL INTERPRETATION:\")\n",
    "if best_metrics['Precision'] > 0.8:\n",
    "    print(f\"   ‚Ä¢ HIGH PRECISION: Low false alarm rate - good for automated blocking\")\n",
    "elif best_metrics['Precision'] > 0.5:\n",
    "    print(f\"   ‚Ä¢ MODERATE PRECISION: Some false alarms - recommend manual review\")\n",
    "else:\n",
    "    print(f\"   ‚Ä¢ LOW PRECISION: High false alarm rate - needs improvement\")\n",
    "\n",
    "if best_metrics['Recall'] > 0.8:\n",
    "    print(f\"   ‚Ä¢ HIGH RECALL: Catches most fraud - good fraud detection coverage\")\n",
    "elif best_metrics['Recall'] > 0.5:\n",
    "    print(f\"   ‚Ä¢ MODERATE RECALL: Misses some fraud - acceptable for initial deployment\")\n",
    "else:\n",
    "    print(f\"   ‚Ä¢ LOW RECALL: Misses significant fraud - needs improvement\")\n",
    "\n",
    "print(f\"\\nüìà BUSINESS RECOMMENDATIONS:\")\n",
    "print(f\"   1. Deploy {best_model_name} for real-time fraud scoring\")\n",
    "print(f\"   2. Set fraud threshold based on business risk tolerance\")\n",
    "print(f\"   3. Implement manual review process for borderline cases\")\n",
    "print(f\"   4. Monitor model performance and retrain regularly\")\n",
    "print(f\"   5. Focus on top {min(10, len(X.columns))} most important features for rule-based systems\")\n",
    "\n",
    "if 'TransactionAmt' in X.columns:\n",
    "    avg_fraud_amount = train_data[train_data['isFraud'] == 1]['TransactionAmt'].mean()\n",
    "    daily_transactions = 1000  # Assume 1000 transactions per day\n",
    "    daily_fraud_rate = train_data['isFraud'].mean()\n",
    "    daily_fraud_prevented = daily_transactions * daily_fraud_rate * best_metrics['Recall'] * avg_fraud_amount\n",
    "    \n",
    "    print(f\"\\nüí∞ ESTIMATED BUSINESS IMPACT (per day):\")\n",
    "    print(f\"   ‚Ä¢ Potential fraud prevented: ${daily_fraud_prevented:,.2f}\")\n",
    "    print(f\"   ‚Ä¢ Fraud detection rate: {best_metrics['Recall']:.1%}\")\n",
    "    print(f\"   ‚Ä¢ False positive rate: {fp/(fp+tn):.1%}\")\n",
    "\n",
    "print(f\"\\nüîß TECHNICAL IMPLEMENTATION:\")\n",
    "print(f\"   ‚Ä¢ Model: {best_model_name} with StandardScaler preprocessing\")\n",
    "print(f\"   ‚Ä¢ Features: {X.shape[1]} engineered features including amount transformations\")\n",
    "print(f\"   ‚Ä¢ Class balancing: {'SMOTE' if IMBALANCE_AVAILABLE else 'Random oversampling'} applied\")\n",
    "print(f\"   ‚Ä¢ Validation: Stratified train-test split with {len(X_test)} test samples\")\n",
    "\n",
    "print(f\"\\n‚úÖ PIPELINE COMPLETION STATUS:\")\n",
    "print(f\"   ‚úì Data loaded and preprocessed\")\n",
    "print(f\"   ‚úì Exploratory analysis completed\")\n",
    "print(f\"   ‚úì Feature engineering applied\")\n",
    "print(f\"   ‚úì Class imbalance handled\")\n",
    "print(f\"   ‚úì {len(fraud_models)} models trained and evaluated\")\n",
    "print(f\"   ‚úì Best model selected and analyzed\")\n",
    "print(f\"   ‚úì Business impact quantified\")\n",
    "print(f\"   ‚úì Ready for production deployment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7bbb69",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "### üéØ **Pipeline Achievements:**\n",
    "\n",
    "1. **‚úÖ Complete End-to-End Pipeline**: From raw data to production-ready fraud detection model\n",
    "2. **‚úÖ Comprehensive EDA**: Deep analysis of fraud patterns and risk factors  \n",
    "3. **‚úÖ Advanced Preprocessing**: Missing value handling, feature engineering, and encoding\n",
    "4. **‚úÖ Class Imbalance Solutions**: SMOTE/oversampling to handle typical fraud data challenges\n",
    "5. **‚úÖ Multiple Model Comparison**: Evaluated 7 different algorithms with proper metrics\n",
    "6. **‚úÖ Business Impact Analysis**: Quantified financial benefits and detection capabilities\n",
    "7. **‚úÖ Production Readiness**: Model interpretation and deployment recommendations\n",
    "\n",
    "### üöÄ **For Production Deployment:**\n",
    "\n",
    "1. **Save the best model** using joblib/pickle for serving\n",
    "2. **Create API endpoint** for real-time fraud scoring\n",
    "3. **Implement monitoring** for model drift and performance\n",
    "4. **Set up retraining pipeline** for continuous learning\n",
    "5. **Design alert system** for high-risk transactions\n",
    "\n",
    "### üìà **Model Improvement Opportunities:**\n",
    "\n",
    "1. **Hyperparameter tuning** for the best performing model\n",
    "2. **Ensemble methods** combining multiple models\n",
    "3. **Deep learning approaches** for complex pattern recognition\n",
    "4. **Time-based features** for transaction sequence analysis\n",
    "5. **External data integration** (device fingerprinting, geolocation)\n",
    "\n",
    "### üí° **Key Learnings:**\n",
    "\n",
    "- **Class imbalance** is critical in fraud detection and must be addressed\n",
    "- **Feature engineering** significantly impacts model performance\n",
    "- **Business metrics** (precision/recall trade-off) are more important than accuracy\n",
    "- **Model interpretability** is crucial for fraud detection systems\n",
    "- **Continuous monitoring** is essential for maintaining effectiveness"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
